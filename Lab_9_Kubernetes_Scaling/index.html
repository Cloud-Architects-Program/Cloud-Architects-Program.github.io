
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-7.1.3">
    
    
      
        <title>Lab 9 Kubernetes Autoscaling - YCIT019</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.e35208c4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.ef6f36e2.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
      <link rel="stylesheet" href="../css/extra.css">
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    <script>function __prefix(e){return new URL("..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#1-kubernetes-autoscaling" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="YCIT019" class="md-header__button md-logo" aria-label="YCIT019" data-md-component="logo">
      
  <img src="../images/k8s.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            YCIT019
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Lab 9 Kubernetes Autoscaling
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="YCIT019" class="md-nav__button md-logo" aria-label="YCIT019" data-md-component="logo">
      
  <img src="../images/k8s.svg" alt="logo">

    </a>
    YCIT019
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../ass1/" class="md-nav__link">
        Assignment1
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../ass1_sol/" class="md-nav__link">
        Assignment1 - Solution
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../ass2/" class="md-nav__link">
        Assignment2
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../ass2_solution/" class="md-nav__link">
        Assignment2 - Solution
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../ass3/" class="md-nav__link">
        Assignment3
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../ass3_solution/" class="md-nav__link">
        Assignment3 - Solution
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../ass4/" class="md-nav__link">
        Assignment4
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../ass5/" class="md-nav__link">
        Assignment5
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_10" type="checkbox" id="__nav_10" checked>
      
      <label class="md-nav__link" for="__nav_10">
        Labs
        <span class="md-nav__icon md-icon"></span>
      </label>
      <nav class="md-nav" aria-label="Labs" data-md-level="1">
        <label class="md-nav__title" for="__nav_10">
          <span class="md-nav__icon md-icon"></span>
          Labs
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
  
  
  
    <li class="md-nav__item">
      <a href="../Lab_2_Docker_basics/" class="md-nav__link">
        Lab 2 Docker Basics
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../Lab_3_Advanced_Docker/" class="md-nav__link">
        Lab 3 Advanced Docker
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../Lab_4_Docker_Images/" class="md-nav__link">
        Lab 4 Managing Docker Images
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../Lab_5_Docker_Compose/" class="md-nav__link">
        Lab 5 Docker Compose
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../Lab_6_Deploy_Kubernetes_kubeadm/" class="md-nav__link">
        Lab 6 Deploy Kubernetes Cluster with Kubeadm
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../Lab_7_Kubernetes_Concepts/" class="md-nav__link">
        Lab 7 Kubernetes Concepts
      </a>
    </li>
  

          
            
  
  
  
    <li class="md-nav__item">
      <a href="../Lab_8_Kubernetes_Features/" class="md-nav__link">
        Lab 8 Kubernetes Features
      </a>
    </li>
  

          
            
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Lab 9 Kubernetes Autoscaling
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Lab 9 Kubernetes Autoscaling
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#0-create-gke-cluster" class="md-nav__link">
    0 Create GKE Cluster
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-resource-and-limits" class="md-nav__link">
    1.1 Resource and Limits
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-creating-a-horizontal-pod-autoscaler-based-on-cpu-usage" class="md-nav__link">
    1.2 Creating a Horizontal Pod Autoscaler based on CPU usage
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-scale-size-of-pods-with-vertical-pod-autoscaling" class="md-nav__link">
    1.3 Scale size of pods with Vertical Pod Autoscaling
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#17-cleaning-up" class="md-nav__link">
    1.7 Cleaning Up
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#0-create-gke-cluster" class="md-nav__link">
    0 Create GKE Cluster
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-resource-and-limits" class="md-nav__link">
    1.1 Resource and Limits
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-creating-a-horizontal-pod-autoscaler-based-on-cpu-usage" class="md-nav__link">
    1.2 Creating a Horizontal Pod Autoscaler based on CPU usage
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-scale-size-of-pods-with-vertical-pod-autoscaling" class="md-nav__link">
    1.3 Scale size of pods with Vertical Pod Autoscaling
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#17-cleaning-up" class="md-nav__link">
    1.7 Cleaning Up
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="1-kubernetes-autoscaling">1 Kubernetes Autoscaling<a class="headerlink" href="#1-kubernetes-autoscaling" title="Permanent link">&para;</a></h1>
<p><strong>Objective</strong></p>
<ul>
<li>Resource &amp; Limits</li>
<li>Scheduling</li>
<li>HPA</li>
<li>VPA</li>
<li>Cluster Autoscaling</li>
<li>Node Auto provisioning (NAP)</li>
</ul>
<h2 id="0-create-gke-cluster">0 Create GKE Cluster<a class="headerlink" href="#0-create-gke-cluster" title="Permanent link">&para;</a></h2>
<p><strong>Step 1</strong> Enable the Google Kubernetes Engine API.</p>
<div class="codehilite"><pre><span></span><code>gcloud services enable container.googleapis.com
</code></pre></div>

<p><strong>Step 2</strong> From the cloud shell, run the following command to create a cluster with 1 node:</p>
<div class="codehilite"><pre><span></span><code>gcloud container clusters create k8s-scaling \
--zone us-central1-c \
--enable-vertical-pod-autoscaling \
--num-nodes 2
</code></pre></div>

<p><strong>Output:</strong></p>
<div class="codehilite"><pre><span></span><code>NAME          LOCATION       MASTER_VERSION   MASTER_IP      MACHINE_TYPE  NODE_VERSION     NUM_NODES  STATUS
k8s-scaling  us-central1-c  1.19.9-gke.1400  34.121.222.83  e2-medium     1.19.9-gke.1400  2          RUNNING
</code></pre></div>

<p><strong>Step 3</strong> Authenticate to the cluster.</p>
<div class="codehilite"><pre><span></span><code>gcloud container clusters get-credentials k8s-scaling --zone us-central1-c
</code></pre></div>

<h2 id="11-resource-and-limits">1.1 Resource and Limits<a class="headerlink" href="#11-resource-and-limits" title="Permanent link">&para;</a></h2>
<p><strong>Step 1:</strong> Inspecting a node’s capacity</p>
<div class="codehilite"><pre><span></span><code>kubectl describe nodes | grep -A15  Capacity:
</code></pre></div>

<p>The output shows two sets of amounts related to the available resources on the node: the node’s capacity and allocatable resources. The capacity represents the total resources of a node, which may not all be available to pods. Certain resources may be reserved for Kubernetes and/or system components. The Scheduler bases its decisions only on the allocatable resource amounts.</p>
<p><strong>Step 2:</strong> Show metrics for a given node</p>
<div class="codehilite"><pre><span></span><code>kubectl top nodes
kubectl top pods -n kube-system
</code></pre></div>

<div class="admonition result">
<p class="admonition-title">Result</p>
<p>CPU and Memory information is available for pods and node through the metrics API.</p>
</div>
<p><strong>Step 3</strong> Create a <code>deployment</code> <code>best_effort.yaml</code> as showed below.
This is regular deployment with  <code>resources</code> configured</p>
<div class="codehilite"><pre><span></span><code>cat &lt;&lt;EOF &gt; best_effort.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubia
spec:
  selector:
    matchLabels:
      app: kubia
  replicas: 3
  template:
    metadata:
      name: kubia
      labels:
        app: kubia
    spec:
      containers:
      - image: luksa/kubia:v1
        name: nodejs
EOF
</code></pre></div>

<p><strong>Step 4</strong> Deploy application</p>
<div class="codehilite"><pre><span></span><code>kubectl create -f best_effort.yaml
</code></pre></div>

<p><strong>Step 5</strong> Verify what is the QOS for this pod:</p>
<div class="codehilite"><pre><span></span><code>kubectl describe pods  | grep QoS
</code></pre></div>

<div class="admonition result">
<p class="admonition-title">Result</p>
<p>If you don't specify request/limits K8s provides <code>Best Effort</code> QOS</p>
</div>
<p><strong>Step 6</strong> Cleanup</p>
<div class="codehilite"><pre><span></span><code>kubectl delete -f best_effort.yaml
</code></pre></div>

<p><strong>Step 7</strong> Create a <code>deployment</code> <code>guaranteed.yaml</code> as showed below.
This is regular deployment with  <code>resources</code> configured</p>
<div class="codehilite"><pre><span></span><code>cat &lt;&lt;EOF &gt; guaranteed.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubia
spec:
  selector:
    matchLabels:
      app: kubia
  replicas: 3
  template:
    metadata:
      name: kubia
      labels:
        app: kubia
    spec:
      containers:
      - image: luksa/kubia:v1
        name: nodejs
        resources:
          requests:
            cpu: 100m
            memory: 200Mi
          limits:
            cpu: 100m
            memory: 200Mi
EOF
</code></pre></div>

<p><strong>Step 8</strong> Deploy application</p>
<div class="codehilite"><pre><span></span><code>kubectl create -f guaranteed.yaml
</code></pre></div>

<p><strong>Step 9</strong> Verify what is the QOS for this pod:</p>
<div class="codehilite"><pre><span></span><code>kubectl describe pods  | grep QoS
</code></pre></div>

<div class="admonition result">
<p class="admonition-title">Result</p>
<p>If you request = limits K8s provides <code>guaranteed</code> QOS</p>
</div>
<p><strong>Step 10</strong> Cleanup</p>
<div class="codehilite"><pre><span></span><code>kubectl delete -f guaranteed.yaml
</code></pre></div>

<p><strong>Step 11</strong> Create a <code>deployment</code> <code>burstable.yaml</code> as showed below.
This is regular deployment with  <code>resources</code> configured</p>
<div class="codehilite"><pre><span></span><code>cat &lt;&lt;EOF &gt; burstable.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubia
spec:
  selector:
    matchLabels:
      app: kubia
  replicas: 3
  template:
    metadata:
      name: kubia
      labels:
        app: kubia
    spec:
      containers:
      - image: luksa/kubia:v1
        name: nodejs
        resources:
          requests:
            cpu: 3000
EOF
</code></pre></div>

<p><strong>Step 12</strong> Deploy application</p>
<div class="codehilite"><pre><span></span><code>kubectl create -f burstable.yaml
</code></pre></div>

<p><strong>Step 13</strong> Verify what is the QOS for this pod:</p>
<div class="codehilite"><pre><span></span><code>kubectl describe pods  | grep QoS
</code></pre></div>

<div class="admonition result">
<p class="admonition-title">Result</p>
<p>If you specify <code>request &gt; or &lt; limits</code>  K8s provides <code>Burstable</code> QOS</p>
</div>
<p><strong>Step 14</strong>  Check status of the Pods </p>
<div class="codehilite"><pre><span></span><code>kubectl get pods
</code></pre></div>

<div class="admonition pending">
<p class="admonition-title">Pending</p>
<p>Why the deployment failed ???</p>
</div>
<p><strong>Step 15</strong> Cleanup</p>
<div class="codehilite"><pre><span></span><code>kubectl delete -f burstable.yaml
</code></pre></div>

<h2 id="12-creating-a-horizontal-pod-autoscaler-based-on-cpu-usage">1.2 Creating a Horizontal Pod Autoscaler based on CPU usage<a class="headerlink" href="#12-creating-a-horizontal-pod-autoscaler-based-on-cpu-usage" title="Permanent link">&para;</a></h2>
<p>Prerequisites: Ensure metrics api is running in your cluster.</p>
<div class="codehilite"><pre><span></span><code>kubectl get pod -n kube-system
</code></pre></div>

<p>Check the status of <code>metrics-server-*****</code> pod status. It should be <code>Running</code></p>
<div class="codehilite"><pre><span></span><code>kubectl top nodes
kubectl top pods -n kube-system
</code></pre></div>

<div class="admonition result">
<p class="admonition-title">Result</p>
<p>CPU and Memory information is available for pods and node through the metrics API.</p>
</div>
<p>Let’s create a horizontal pod autoscaler now and configure it to scale pods
based on their CPU utilization.</p>
<p><strong>Step 1</strong> Create a <code>deployment.yaml</code> as showed below.
This is regular deployment with  <code>resources</code> configured</p>
<div class="codehilite"><pre><span></span><code>cat &lt;&lt;EOF &gt; deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kubia
spec:
  selector:
    matchLabels:
      app: kubia
  replicas: 3
  template:
    metadata:
      name: kubia
      labels:
        app: kubia
    spec:
      containers:
      - image: luksa/kubia:v1
        name: nodejs
        resources:
          requests:
            cpu: 100m
EOF
</code></pre></div>

<p><strong>Step 2</strong> Deploy application</p>
<div class="codehilite"><pre><span></span><code>kubectl create -f deployment.yaml
</code></pre></div>

<p><strong>Step 3</strong> After creating the deployment, to enable horizontal autoscaling of its pods, you need to create a HorizontalPodAutoscaler (HPA) object and point it to the deployment.</p>
<div class="codehilite"><pre><span></span><code>kubectl autoscale deployment kubia --cpu-percent=30 --min=1 --max=5
</code></pre></div>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This creates the HPA object for us and sets the deployment called <code>kubia</code> as the scaling target. We’re setting the target CPU utilization of the pods to 30% and specifying the minimum and maximum number of replicas. The autoscaler will thus constantly keep adjusting the number of replicas to keep their CPU utilization around 30%, but it will never scale down to less than 1 or scale up to more than 5 replicas.</p>
</div>
<p><strong>Step 4</strong> Verify definition of the Horizontal Pod Autoscaler resource to gain a better understanding of it:</p>
<div class="codehilite"><pre><span></span><code>kubectl get hpa kubia -o yaml
</code></pre></div>

<p><strong>Result:</strong></p>
<div class="codehilite"><pre><span></span><code>apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
...
spec:
  maxReplicas: 5
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: kubia
  targetCPUUtilizationPercentage: 30
status:
  currentReplicas: 0
  desiredReplicas: 0
</code></pre></div>

<p><strong>Step 5</strong> Take a closer look at the HPA and notice that it is still not ready to do the autoscaling.</p>
<div class="codehilite"><pre><span></span><code>kubectl describe hpa kubia
</code></pre></div>

<p><strong>Results</strong></p>
<div class="codehilite"><pre><span></span><code>Events:
  Type     Reason                        Age                   From                       Message
  ----     ------                        ----                  ----                       -------
  Warning  FailedGetResourceMetric       2m29s                 horizontal-pod-autoscaler  unable to get metrics for resource cpu: no metrics returned from resource metrics API
  Warning  FailedComputeMetricsReplicas  2m29s                 horizontal-pod-autoscaler  failed to compute desired number of replicas based on listed metrics for Deployment/default/kubia: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: unable to get metrics for resource cpu: no metrics returned from resource metrics API
  Warning  FailedGetResourceMetric       118s (x3 over 2m14s)  horizontal-pod-autoscaler  did not receive metrics for any ready pods
  Warning  FailedComputeMetricsReplicas  118s (x3 over 2m14s)  horizontal-pod-autoscaler  failed to compute desired number of replicas based on listed metrics for Deployment/default/kubia: invalid metrics (1 invalid out of 1), first error is: failed to get cpu utilization: did not receive metrics for any ready pods
</code></pre></div>

<p>Given that historical data is not available yet, you will see the above in the events section.</p>
<p>Give it a minute or so and try again. Eventually, you will see the following in the <code>Events</code> section.</p>
<div class="codehilite"><pre><span></span><code>  Normal   SuccessfulRescale             41s                    horizontal-pod-autoscaler  New size: 1; reason: All metrics below target
</code></pre></div>

<p>If you take a look at the <code>kubia</code> deployment, you will see it was scaled down from 3 pods to 1 pod.</p>
<p><strong>Step 6</strong> Create a service</p>
<div class="codehilite"><pre><span></span><code>kubectl expose deployment kubia --port=80 --target-port=8080
</code></pre></div>

<p><strong>Step 7</strong> Start another terminal session and run:</p>
<div class="codehilite"><pre><span></span><code>watch -n 1 kubectl get hpa,deployment
</code></pre></div>

<p><strong>Step 8</strong> Generate load to the Application</p>
<div class="codehilite"><pre><span></span><code>kubectl run -it --rm --restart=Never loadgenerator --image=busybox \
-- sh -c &quot;while true; do wget -O - -q http://kubia.default; done&quot;
</code></pre></div>

<p><strong>Step 9</strong> Observe autoscaling
In the other terminal you will start noticing that the deployment is being scaled up.</p>
<p><strong>Step 10</strong> Terminate both sessions by pressing <code>Ctrl+c</code></p>
<h2 id="13-scale-size-of-pods-with-vertical-pod-autoscaling">1.3 Scale size of pods with Vertical Pod Autoscaling<a class="headerlink" href="#13-scale-size-of-pods-with-vertical-pod-autoscaling" title="Permanent link">&para;</a></h2>
<p><strong>Step 1</strong> Verify that Vertical Pod Autoscaling has already been enabled on the cluster. We enabled VPA when we created the cluster, by using <code>--enable-vertical-pod-autoscaling</code>. This command can be handy if you want to check VPA on an existing cluster.</p>
<div class="codehilite"><pre><span></span><code>gcloud container clusters describe k8s-scaling --zone us-central1-c | grep ^verticalPodAutoscaling -A 1
</code></pre></div>

<p><strong>Step 2</strong> Apply the hello-server deployment to your cluster</p>
<div class="codehilite"><pre><span></span><code>kubectl create deployment hello-server --image=gcr.io/google-samples/hello-app:2.0
</code></pre></div>

<p><strong>Step 3</strong> Ensure the deployment was successfully created</p>
<div class="codehilite"><pre><span></span><code>kubectl get deployment hello-server
</code></pre></div>

<p><strong>Step 4</strong> Assign a CPU resource request of 100m to the deployment</p>
<div class="codehilite"><pre><span></span><code>kubectl set resources deployment hello-server --requests=cpu=100m
</code></pre></div>

<p><strong>Step 5</strong> Inspect the container specifics of the <code>hello-server</code> pods, find <code>Requests</code> section, and notice that this pod is currently requesting the 450m CPU we assigned.</p>
<div class="codehilite"><pre><span></span><code>kubectl describe pod hello-server | sed -n &quot;/Containers:$/,/Conditions:/p&quot;
</code></pre></div>

<p><strong>Output</strong></p>
<div class="codehilite"><pre><span></span><code>Containers:
  hello-app:
    Image:      gcr.io/google-samples/hello-app:2.0
    Port:       &lt;none&gt;
    Host Port:  &lt;none&gt;
    Requests:
      cpu:        100m
    Environment:  &lt;none&gt;
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-rw2gr (ro)
Conditions:
Containers:
  hello-app:
    Container ID:   containerd://e9bb428186f5d6a6572e81a5c0a9c37118fd2855f22173aa791d8429f35169a6
    Image:          gcr.io/google-samples/hello-app:2.0
    Image ID:       gcr.io/google-samples/hello-app@sha256:37e5287945774f27b418ce567cd77f4bbc9ef44a1bcd1a2312369f31f9cce567
    Port:           &lt;none&gt;
    Host Port:      &lt;none&gt;
    State:          Running
      Started:      Wed, 09 Jun 2021 11:34:15 +0000
    Ready:          True
    Restart Count:  0
    Environment:    &lt;none&gt;
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-rw2gr (ro)
Conditions:
</code></pre></div>

<p><strong>Step 6</strong> Create a manifest for you Vertical Pod Autoscale</p>
<div class="codehilite"><pre><span></span><code>cat &lt;&lt; EOF &gt; hello-vpa.yaml
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: hello-server-vpa
spec:
  targetRef:
    apiVersion: &quot;apps/v1&quot;
    kind:       Deployment
    name:       hello-server
  updatePolicy:
    updateMode: &quot;Off&quot;
EOF
</code></pre></div>

<p><strong>Step 7</strong> Apply the manifest for <code>hello-vpa</code></p>
<div class="codehilite"><pre><span></span><code>kubectl apply -f hello-vpa.yaml
</code></pre></div>

<p><strong>Step 8</strong> Wait a minute, and then view the VerticalPodAutoscaler</p>
<div class="codehilite"><pre><span></span><code>kubectl describe vpa hello-server-vpa
</code></pre></div>

<p><strong>Step 9</strong> Locate the "Container Recommendations" at the end of the output from the <code>describe</code> command. If you don't see it, wait a little longer and try the previous command again. When it appears, you'll see several different recommendation types, each with values for CPU and memory:</p>
<ul>
<li>Lower Bound: this is the lower bound number VPA looks at for triggering a resize. If your pod utilization goes below this, VPA will delete the pod and scale it down.</li>
<li>Target: this is the value VPA will use when resizing the pod.</li>
<li>Uncapped Target: if no minimum or maximum capacity is assigned to the VPA, this will be the target utilization for VPA.</li>
<li>Upper Bound: this is the upper bound number VPA looks at for triggering a resize. If your pod utilization goes above this, VPA will delete the pod and scale it up.</li>
</ul>
<p>Notice that the VPA is recommending new values for CPU instead of what we set, and also giving you a suggested number for how much memory should be requested. We can at this point manually apply these suggestions, or allow VPA to apply them.</p>
<p><strong>Step 10</strong> Update the manifest to set the policy to Auto and apply the configuration</p>
<div class="codehilite"><pre><span></span><code>sed -i &#39;s/Off/Auto/g&#39; hello-vpa.yaml
kubectl apply -f hello-vpa.yaml
</code></pre></div>

<p>In order to resize a pod, Vertical Pod Autoscaler will need to delete that pod and recreate it with the new size. By default, to avoid downtime, VPA will not delete and resize the last active pod. Because of this, you will need at least 2 replicas to see VPA make any changes.</p>
<p><strong>Step 11</strong> Scale hello-server deployment to 2 replicas:</p>
<div class="codehilite"><pre><span></span><code>kubectl scale deployment hello-server --replicas=2
</code></pre></div>

<p><strong>Step 12</strong> Watch your pods</p>
<div class="codehilite"><pre><span></span><code>kubectl get pods -w
</code></pre></div>

<p><strong>Step 13</strong> The VPA should have resized your pods in the hello-server deployment. Inspect your pods:</p>
<div class="codehilite"><pre><span></span><code>kubectl describe pod hello-server | sed -n &quot;/Containers:$/,/Conditions:/p&quot;
</code></pre></div>

<h2 id="17-cleaning-up">1.7 Cleaning Up<a class="headerlink" href="#17-cleaning-up" title="Permanent link">&para;</a></h2>
<p><strong>Step 1</strong> Delete the cluster</p>
<div class="codehilite"><pre><span></span><code>gcloud container clusters delete k8s-scaling
</code></pre></div>

<!-- ## 1.4 GKE Cluster Autoscaler (Demo)
**Step 1**

<div class="codehilite"><pre><span></span><code>
</code></pre></div>


**Step 2**

<div class="codehilite"><pre><span></span><code>
</code></pre></div>


**Step 3**

<div class="codehilite"><pre><span></span><code>
</code></pre></div>


**Step 4**

<div class="codehilite"><pre><span></span><code>
</code></pre></div>


**Step 5**

<div class="codehilite"><pre><span></span><code>
</code></pre></div>


**Step 6**

<div class="codehilite"><pre><span></span><code>
</code></pre></div>


**Step 7**

<div class="codehilite"><pre><span></span><code>
</code></pre></div>


## 1.5 Node Auto Provisioning (NAP)
**Step 1**
**Step 2**
**Step 3**
**Step 4**
**Step 5** -->
                
              
              
                


              
            </article>
          </div>
        </div>
        
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        <a href="../Lab_8_Kubernetes_Features/" class="md-footer__link md-footer__link--prev" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Lab 8 Kubernetes Features
            </div>
          </div>
        </a>
      
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
        
      </div>
      
  <div class="md-footer-social">
    
      
      
        
        
      
      <a href="https://twitter.com/googlecloud" target="_blank" rel="noopener" title="twitter.com" class="md-footer-social__link">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
      </a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}, "search": "../assets/javascripts/workers/search.fe42c31b.min.js", "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.4ea5477f.min.js"></script>
      
    
  </body>
</html>