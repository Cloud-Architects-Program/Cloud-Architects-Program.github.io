{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Cloud Architecture \u00b6 Class Objectives: The power of containerization and its distinction from virtualization; features of the Linux kernel underpinning containerization; how to set up a Docker environment, build containers, and use an orchestration tool, namely, Kubernetes; additional tools for monitoring, sharing, and deploying applications.","title":"Home"},{"location":"#cloud-architecture","text":"Class Objectives: The power of containerization and its distinction from virtualization; features of the Linux kernel underpinning containerization; how to set up a Docker environment, build containers, and use an orchestration tool, namely, Kubernetes; additional tools for monitoring, sharing, and deploying applications.","title":"Cloud Architecture"},{"location":"Lab_2_Docker_basics/","text":"Lab 2 Docker basics Objective: Practice to run Docker containers 1 Docker basics \u00b6 1.1 Show running containers \u00b6 Step 1 Run docker ps to show running containers: docker ps Step 2 The output shows that there are no running containers at the moment. Use the command docker ps -a to list all containers including the ones has been stopped: docker ps -a Output: CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6e6db2a24a8e hello-world \"/hello\" 15 minutes ago Exited (0) 15 min dreamy_nobel Review the collumns CONTAINER ID , STATUS , COMMAND , PORTS , NAMES . In the previous section we started one container and the command docker ps -a shows it as Exited . Note You can name your own containers with --name when you use docker run. If you do not provide a name, Docker will generate a random one like the one you have. Question Why Docker names are random? How docker containers named? Step 3 Let\u2019s run the command docker images to show all the images on your local system: docker images As you see, there is only one image that was downloaded from the Docker Hub. 1.2 Specify a container main process \u00b6 Step 1 Let\u2019s run our own \"hello world\" container. For that we will use the official Ubuntu image : docker run ubuntu /bin/echo 'Hello world' Output: Unable to find image 'ubuntu:latest' locally latest: Pulling from library/ubuntu ... Status: Downloaded newer image for ubuntu:latest Hello world As you see, Docker downloaded the image ubuntu because it was not on the local machine. Step 2 Let\u2019s run the command docker images again: docker images Output: REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu latest 42118e3df429 11 days ago 124.8 MB hello-world latest c54a2cc56cbb 4 weeks ago 1.848 kB Step 3 If you run the same \"hello world\" container again, Docker will use a local copy of the image: docker run ubuntu /bin/echo 'Hello world' Output: Hello world Question Compare Ubuntu Docker image with ISO image or with Cloud VM image. Why the size is so different ? Summary Pulling docker images from Docker Hub takes sometime. This time depends on: How large is the image? How fast is the network to Internet ? However, it is still much faster than booting traditional OS with Ubuntu on VM. If image already pulled on local host it takes fraction of a second to start a container. Running application in docker containers considered as a best practice for running CI/CD pipelines as it considerably faster than using VMs and reduce time for deploying a test environments. 1.3 Specify an image version \u00b6 Step 1 As you see, Docker has downloaded the ubuntu:latest image. You can see Ubuntu version by running the following command: docker run ubuntu /bin/cat /etc/issue.net Output: Ubuntu 16.04 LTS Let\u2019s say you need a previous Ubuntu LTS release. In this case, you can specify the version you need: docker run ubuntu:14.04 /bin/cat /etc/issue.net Output: Unable to find image 'ubuntu:14.04' locally 14.04: Pulling from library/ubuntu ... Status: Downloaded newer image for ubuntu:14.04 Ubuntu 14.04.4 LTS Step 2 The docker images command should show that we have 3 Ubuntu images downloaded locally: docker images Output: REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu latest 42118e3df429 11 days ago 124.8 MB ubuntu 14.04 0ccb13bf1954 11 days ago 188 MB hello-world latest c54a2cc56cbb 4 weeks ago 1.848 kB Tip Running CI/CD pipeline with Docker using latest tag considered as a Bad Practice. Instead consider using: Versioning SHA tagging. 1.4 Run an interactive container \u00b6 Step 1 Let\u2019s use the ubuntu image to run an interactive bash session and inspect what is running inside our docker image. To achive that we going to use -i and -t flags. The -i is shorthand for --interactive , which instructs Docker to keep stdin open so that we can send commands to the sprocess. The -t flag is short for --tty and allocates a pseudo-TTY or terminal inside of the session. docker run -it ubuntu /bin/bash root@17d8bdeda98e:/# Result We get a bash shell prompt inside of the container. Note Bash prompt is not availabe for all docker images. Step 2 Let's print the system information of the latest Ubuntu image: root@17d8bdeda98e:/# uname -a Linux 17d8bdeda98e 3.19.0-31-generic ... Step 3 Let's verify what Ubuntu version is run by latest image of ubuntu: root@17d8bdeda98e:/# lsb_release -a bash: lsb_release: command not found Failure Why the standard Ubuntu command that checks version of OS is not working as expeced ? Step 4 Let's verify Ubuntu version using alternative way by checking /etc/lsb-release file. root@8cbcbd0fe8d2:/# cat /etc/lsb-release DISTRIB_ID=Ubuntu DISTRIB_RELEASE=16.04 DISTRIB_CODENAME=xenial DISTRIB_DESCRIPTION=\"Ubuntu 16.04.3 LTS\" Step 5 Let's compare the number of executable binaries availabe inside of the docker image versus Cloud VM that we running our class environment. First, run ls command on /bin and /usr/bin directories inside of the running ubuntu container as well as dpkg --list command that shows total number of installed packages: root@8cbcbd0fe8d2:/# ls /bin | wc -l 86 root@8cbcbd0fe8d2:/# ls /usr/bin | wc -l 233 root@eb11cd0b4106:/# dpkg --list | wc -l 101 Step 6 Use the exit command or press Ctrl-D to exit the interactive bash session back to Cloud VM. root@eb11cd0b4106:/# exit Step 7 Now run ls command on /bin and /usr/bin directories on Cloud VM that we using as our class environment: cca-user@userx-docker-vm:~$ ls /bin | wc -l 171 cca-user@userx-docker-vm:~$ ls /usr/bin | wc -l 660 cca-user@userx-docker-vm:~$ dpkg --list | wc -l 463 Result Official Docker container has much less binaries and packages installed vs Ubuntu Cloud Image. Summary Some of the use cases running docker containers in interactive mode are: Troubleshooting containerized applications Deploying and running containerized application on the existing production systems without affecting it. We've also learned that an official Docker \"minimal\" ubuntu image, does not include lsb_release command, as well as many other commands and packages that can be found in Official Ubuntu ISO image . The docker images are ment to contain only required core system commands and functions to make Images as light as possible. That say you can still install required packages using apt-get install , however this may increase size of docker image considerably. Hint While Docker Ubuntu image we used so far or Docker Centos image are very familiar to users and can be good starting point for learning docker containers. Using them in production or development considered as a Bad Practice. This is due those images still considered as heavy and potentially contain a lot more valnurabilities compare to specialized images. To reduce image pull time from docker hub and follow the best secuirity practices consider using specialized images that works well with you underlining code (Node image for NodeJS applications and etc.). Examples of specialized images are: Alpine Linux Node Atomic In fact, not so long ago all the official Docker Images in Docker-Hub has been moved to use Alpine Image . Step 8 Finally let\u2019s check that when the shell process has finished, the container stops: docker ps 1.5 Run a container in a background \u00b6 Now we know how to connect to running container and execute commands in it. However in most cases you just want run a container in a background so it can do a specific action. Step 1 Run a container in a background using the -d command line argument: docker run -d ubuntu /bin/sh -c \"while true; do date; echo hello world; sleep 1; done\" Result Command should return the container ID. Step 2 Let\u2019s use the docker ps command to see running containers: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ac231579e57f ubuntu \"/bin/sh -c 'while tr\" 1 minute ago Up 11 minute evil_golick Note Container id is going to be different in your case Hint Instead of using full container-id when building commands, it is possible simply type first few characters of container-id, to make things nice and easy. Step 3 Let\u2019s use container-id to show the container standard output: docker logs <container-id> Thu Jan 26 00:23:45 UTC 2017 hello world Thu Jan 26 00:23:46 UTC 2017 hello world Thu Jan 26 00:23:47 UTC 2017 hello world ... As you can see, in the docker ps command output, the auto generated container name is evil_golick (your container can have a different name). Step 4 Now, instead of using docker contaier-id use container name to show the container standard output: docker logs <name> Thu Jan 26 00:23:51 UTC 2017 hello world Thu Jan 26 00:23:52 UTC 2017 hello world Thu Jan 26 00:23:53 UTC 2017 hello world ... Step 5 Finally, let\u2019s stop our container: docker stop <name> Step 6 Check, that there are no running containers: docker ps Summary docker logs is a very usefull command to troubleshoot containers, and going to be used very often both for Docker and Kubernertes troubleshooting. 1.6 Accessing Containers from the Internet \u00b6 Step 1 Let\u2019s run a simple web application. We will use the existing image training/webapp, which contains a Python Flask application: docker run -d -P training/webapp python app.py ... Status: Downloaded newer image for training/webapp:latest 6e88f42d3d853762edcbfe1fe73fdc5c48865275bc6df759b83b0939d5bd2456 In the command above we specified the main process (python app.py), the -d command line argument, which tells Docker to run the container in the background. The -P command line argument tells Docker to map any required network ports inside our container to our host. This allows us to access the web application in the container. Step 2 Use the docker ps command to list running containers: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6e88f42d3d85 training/webapp \"python app.py\" 3 minutes ago Up 3 minutes 0.0.0.0:32768->5000/tcp determined_torvalds The PORTS column contains the mapped ports. In our case, Docker has exposed port 5000 (the default Python Flask port) on port 32768 (can be different in your case). Step 3 The docker port command shows the exposed port. We will use the container name (determined_torvalds in the example above, it can be different in your case): docker port <name> 5000 0.0.0.0:32768 Step 4 Let\u2019s check that we can access the web application exposed port: curl http://localhost:<port>/ Result Hello world! Step 5 Let\u2019s stop our web application for now: docker stop <name> Step 6 We want to manually specify the local port to expose (-p argument). Let\u2019s use the standard HTTP port 80. We also want to specify the container name (--name argument): docker run -d -p 80:5000 --name webapp training/webapp python app.py Step 7 Let\u2019s check that the port 80 is exposed: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 249476631f7d training/webapp \"python app.py\" 1 minute ago Up 1 minute 0.0.0.0:80->5000/tcp webapp curl http://localhost/ Result `Hello world!`` Step 8 You can also observe Hello world! webapp from you laptop, for that you need to use you public VM IP that can be gather from VMs list: Your_VM_Public_IP Than paste VM Public IP address in you browser. Result Our web-app can be accessed from Internet! 1.7 Restart a container \u00b6 Step 1 Let\u2019s stop the container with web application: docker stop webapp The main process inside of the container will receive SIGTERM, and after a grace period, SIGKILL. Step 2 You can start the container later using the docker start command: docker start webapp Step 3 Check that the web application works: curl http://localhost/ Hello world! Step 4 You also can restart the running container using the docker restart command. docker restart webapp Step 4 Run docker ps command and check STATUS field: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS 6e400179070f training/webapp \"python app.py\" 25 minutes ago Up 3 seconds 1.8 Ensuring Container Uptime \u00b6 Docker considers any containers to exit with a non-zero exit code to have crashed. By default a crashed container will remain stopped. Step 1 Start the container that outputs a message and then exits with code 1 to simulate a crash. docker run -d --name restart-default scrapbook/docker-restart-example docker ps -a | grep restart-default CONTAINER ID IMAGE CREATED STATUS NAMES c854289d2f39 scrapbook/docker-restart-example 5 seconds ago Exited 3 sec ago restart-default $ docker logs restart-default Sun Sep 17 20:34:55 UTC 2017 Booting up... Result Container crushed and exited. However, there are several ways to ensure that you container up and running even if it\u2019s restarts. Step 2 The option --restart=on-failure : allows you to say how many times Docker should try again: docker run -d --name restart-3 --restart=on-failure:3 scrapbook/docker-restart-example docker logs restart-3 Thu Apr 20 14:01:27 UTC 2017 Booting up... Thu Apr 20 14:01:28 UTC 2017 Booting up... Thu Apr 20 14:01:29 UTC 2017 Booting up... Thu Apr 20 14:01:31 UTC 2017 Booting up... Step 3 Finally, Docker can always restart a failed container. In this case, Docker will keep trying until the container is explicitly told to stop. docker run -d --name restart-always --restart=always scrapbook/docker-restart-example docker logs restart-always Step 4 After sometime stop running docker container, as it will be keep failing and starting again: docker stop restart-always 1.9 Inspect a container \u00b6 Step 1 You can use the docker inspect command to see the configuration and status information for the specified container: docker inspect webapp [ { \"Id\": \"249476631f7d...\", \"Created\": \"2016-08-02T23:42:56.932135327Z\", \"Path\": \"python\", \"Args\": [ \"app.py\" ], \"State\": { \"Status\": \"running\", \"Running\": true, \"Paused\": false, \"Restarting\": false, \"OOMKilled\": false, \"Dead\": false, \"Pid\": 16055, \"ExitCode\": 0, \"Error\": \"\", ... Step 2 You can specify a filter (-f command line argument) to show only specific elements. For example: docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' webapp 172.17.0.2 The command returns the IP address of the container. 1.10 Interacting with containers \u00b6 In some cases using docker log is not enough to undertand issues and you want to login inside of running VM. Also sometimes you package you applicaiton and in order to run it you need to login inside of container and execute and leave it running in background. Below provded few ways to interacting with containers that can help to achive descrined use cases. 1.10.1 Detach from Interactive container \u00b6 In Module, 1.4 Run an interactive container we run an Ubuntu container with -it flag and able directly login inside of the container to interact with it, however after we exited contianer using Ctrl-D or exit command container stopped. However you can exit from Interactive mode without stoping a container. Let's demonstrate how this works: Step 1 Start Ubunu container in interactive mode: docker run -it ubuntu /bin/bash Step 2 Run watch date command inside running container in order to exit date command every 2 seconds. root@1d688a9f4ed4:/# watch date Step 3 Detach from a container and leave it running using the CTRL-p CTRL-q key sequence. Step 4 Verify that Ubuntu container is still running: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS NAMES 1d688a9f4ed4 ubuntu \"/bin/bash\" 1 minutes ago Up 1 minutes admiring_lovelace Result Great you were able to detach from Docker container without stopping it, while it is executing a process in it. What about attaching back to container ? Important CTRL-p CTRL-q sequence key only works if docker contaienr started with -it command! 1.11.2 Attach to a container \u00b6 Now let's get back and attach to our running Ubuntu image. For that docker provides docker attach command. docker attach <container name> Every 2.0s: date Mon Sep 18 00:08:57 2017 Summary docker attach attaches your contairs terminal\u2019s standard input, output, and error (or any combination of the 3) to a running container. This allows you to view its ongoing output or to control it interactively, as though the commands were running directly in your terminal. 1.11.3 Execute a process in a container \u00b6 Step 1 Let verify if webapp container is still running docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 249476631f7d training/webapp \"python app.py\" 1 minute ago Up 1 minute 0.0.0.0:80->5000/tcp webapp If not running start it with following command: $ docker run -d -p 80:5000 --name webapp training/webapp python app.py other wise skip to next step . Step 2 Use the docker exec command to execute a command in the running container. For example: docker exec webapp ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.2 0.0 52320 17384 ? Ss 00:11 0:00 python app.py root 26 0.0 0.0 15572 2104 ? Rs 00:12 0:00 ps aux The same command with the -it command line argument can be used to run an interactive session in the container: docker exec -it webapp bash root@249476631f7d:/opt/webapp# ps auxw ps auxw USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.0 52320 17384 ? Ss 00:11 0:00 python app.py root 32 0.0 0.0 18144 3064 ? Ss 00:14 0:00 bash root 47 0.0 0.0 15572 2076 ? R+ 00:16 0:00 ps auxw Step 2 Use the exit command or press Ctrl-D to exit the interactive bash session: root@249476631f7d:/opt/webapp# exit Summary docker exec is one of the most usefull docker commands used for troubleshooting containers. 1.12 Copy files to/from container \u00b6 The docker cp command allows you to copy files from the container to the local machine or from the local file system to the container. This command works for a running or stopped container. Step 1 Let\u2019s copy the container\u2019s app.py file to the local machine: docker cp webapp:/opt/webapp/app.py . Step 2 Edit the local app.py file. For example, change the line return 'Hello '+provider+'!' to return 'Hello '+provider+'!!!'. Copy the modified file back and restart the container: docker cp app.py webapp:/opt/webapp/ docker restart webapp Step 3 Check that the modified web application works:: curl http://localhost/ Result `Hello world!!!`` 1.12 Remove containers \u00b6 Now let's clean up the environment and at the same time learn how delete containers. Step 1 First list running containers: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 81c4c66baaf9 training/webapp \"python app.py\" 1 minute ago Up 1 minute 0.0.0.0:80->5000/tcp webapp Step 2 Than try to delete running container using docker rm <container_id> docker rm $container_id Error response from daemon: You cannot remove a running container 81c4c66baaf9. Stop the container before attempting removal or force remove. Failure Docker containers needs to be first stopped or deleted using --force flag. docker rm $container_id -f Alternatively, you can run stop and rm in sequence: docker stop 81c4c66baaf9 docker rm 81c4c66baaf9 Summary We've learned a lot of docker commands which are very handy to know both when using Docker and Kubernetes. In the next Module we going to deep dive in to details of how networking and storage works in Docker.","title":"Lab 2 Docker Basics"},{"location":"Lab_2_Docker_basics/#1-docker-basics","text":"","title":"1 Docker basics"},{"location":"Lab_2_Docker_basics/#11-show-running-containers","text":"Step 1 Run docker ps to show running containers: docker ps Step 2 The output shows that there are no running containers at the moment. Use the command docker ps -a to list all containers including the ones has been stopped: docker ps -a Output: CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6e6db2a24a8e hello-world \"/hello\" 15 minutes ago Exited (0) 15 min dreamy_nobel Review the collumns CONTAINER ID , STATUS , COMMAND , PORTS , NAMES . In the previous section we started one container and the command docker ps -a shows it as Exited . Note You can name your own containers with --name when you use docker run. If you do not provide a name, Docker will generate a random one like the one you have. Question Why Docker names are random? How docker containers named? Step 3 Let\u2019s run the command docker images to show all the images on your local system: docker images As you see, there is only one image that was downloaded from the Docker Hub.","title":"1.1 Show running containers"},{"location":"Lab_2_Docker_basics/#12-specify-a-container-main-process","text":"Step 1 Let\u2019s run our own \"hello world\" container. For that we will use the official Ubuntu image : docker run ubuntu /bin/echo 'Hello world' Output: Unable to find image 'ubuntu:latest' locally latest: Pulling from library/ubuntu ... Status: Downloaded newer image for ubuntu:latest Hello world As you see, Docker downloaded the image ubuntu because it was not on the local machine. Step 2 Let\u2019s run the command docker images again: docker images Output: REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu latest 42118e3df429 11 days ago 124.8 MB hello-world latest c54a2cc56cbb 4 weeks ago 1.848 kB Step 3 If you run the same \"hello world\" container again, Docker will use a local copy of the image: docker run ubuntu /bin/echo 'Hello world' Output: Hello world Question Compare Ubuntu Docker image with ISO image or with Cloud VM image. Why the size is so different ? Summary Pulling docker images from Docker Hub takes sometime. This time depends on: How large is the image? How fast is the network to Internet ? However, it is still much faster than booting traditional OS with Ubuntu on VM. If image already pulled on local host it takes fraction of a second to start a container. Running application in docker containers considered as a best practice for running CI/CD pipelines as it considerably faster than using VMs and reduce time for deploying a test environments.","title":"1.2 Specify a container main process"},{"location":"Lab_2_Docker_basics/#13-specify-an-image-version","text":"Step 1 As you see, Docker has downloaded the ubuntu:latest image. You can see Ubuntu version by running the following command: docker run ubuntu /bin/cat /etc/issue.net Output: Ubuntu 16.04 LTS Let\u2019s say you need a previous Ubuntu LTS release. In this case, you can specify the version you need: docker run ubuntu:14.04 /bin/cat /etc/issue.net Output: Unable to find image 'ubuntu:14.04' locally 14.04: Pulling from library/ubuntu ... Status: Downloaded newer image for ubuntu:14.04 Ubuntu 14.04.4 LTS Step 2 The docker images command should show that we have 3 Ubuntu images downloaded locally: docker images Output: REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu latest 42118e3df429 11 days ago 124.8 MB ubuntu 14.04 0ccb13bf1954 11 days ago 188 MB hello-world latest c54a2cc56cbb 4 weeks ago 1.848 kB Tip Running CI/CD pipeline with Docker using latest tag considered as a Bad Practice. Instead consider using: Versioning SHA tagging.","title":"1.3 Specify an image version"},{"location":"Lab_2_Docker_basics/#14-run-an-interactive-container","text":"Step 1 Let\u2019s use the ubuntu image to run an interactive bash session and inspect what is running inside our docker image. To achive that we going to use -i and -t flags. The -i is shorthand for --interactive , which instructs Docker to keep stdin open so that we can send commands to the sprocess. The -t flag is short for --tty and allocates a pseudo-TTY or terminal inside of the session. docker run -it ubuntu /bin/bash root@17d8bdeda98e:/# Result We get a bash shell prompt inside of the container. Note Bash prompt is not availabe for all docker images. Step 2 Let's print the system information of the latest Ubuntu image: root@17d8bdeda98e:/# uname -a Linux 17d8bdeda98e 3.19.0-31-generic ... Step 3 Let's verify what Ubuntu version is run by latest image of ubuntu: root@17d8bdeda98e:/# lsb_release -a bash: lsb_release: command not found Failure Why the standard Ubuntu command that checks version of OS is not working as expeced ? Step 4 Let's verify Ubuntu version using alternative way by checking /etc/lsb-release file. root@8cbcbd0fe8d2:/# cat /etc/lsb-release DISTRIB_ID=Ubuntu DISTRIB_RELEASE=16.04 DISTRIB_CODENAME=xenial DISTRIB_DESCRIPTION=\"Ubuntu 16.04.3 LTS\" Step 5 Let's compare the number of executable binaries availabe inside of the docker image versus Cloud VM that we running our class environment. First, run ls command on /bin and /usr/bin directories inside of the running ubuntu container as well as dpkg --list command that shows total number of installed packages: root@8cbcbd0fe8d2:/# ls /bin | wc -l 86 root@8cbcbd0fe8d2:/# ls /usr/bin | wc -l 233 root@eb11cd0b4106:/# dpkg --list | wc -l 101 Step 6 Use the exit command or press Ctrl-D to exit the interactive bash session back to Cloud VM. root@eb11cd0b4106:/# exit Step 7 Now run ls command on /bin and /usr/bin directories on Cloud VM that we using as our class environment: cca-user@userx-docker-vm:~$ ls /bin | wc -l 171 cca-user@userx-docker-vm:~$ ls /usr/bin | wc -l 660 cca-user@userx-docker-vm:~$ dpkg --list | wc -l 463 Result Official Docker container has much less binaries and packages installed vs Ubuntu Cloud Image. Summary Some of the use cases running docker containers in interactive mode are: Troubleshooting containerized applications Deploying and running containerized application on the existing production systems without affecting it. We've also learned that an official Docker \"minimal\" ubuntu image, does not include lsb_release command, as well as many other commands and packages that can be found in Official Ubuntu ISO image . The docker images are ment to contain only required core system commands and functions to make Images as light as possible. That say you can still install required packages using apt-get install , however this may increase size of docker image considerably. Hint While Docker Ubuntu image we used so far or Docker Centos image are very familiar to users and can be good starting point for learning docker containers. Using them in production or development considered as a Bad Practice. This is due those images still considered as heavy and potentially contain a lot more valnurabilities compare to specialized images. To reduce image pull time from docker hub and follow the best secuirity practices consider using specialized images that works well with you underlining code (Node image for NodeJS applications and etc.). Examples of specialized images are: Alpine Linux Node Atomic In fact, not so long ago all the official Docker Images in Docker-Hub has been moved to use Alpine Image . Step 8 Finally let\u2019s check that when the shell process has finished, the container stops: docker ps","title":"1.4 Run an interactive container"},{"location":"Lab_2_Docker_basics/#15-run-a-container-in-a-background","text":"Now we know how to connect to running container and execute commands in it. However in most cases you just want run a container in a background so it can do a specific action. Step 1 Run a container in a background using the -d command line argument: docker run -d ubuntu /bin/sh -c \"while true; do date; echo hello world; sleep 1; done\" Result Command should return the container ID. Step 2 Let\u2019s use the docker ps command to see running containers: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ac231579e57f ubuntu \"/bin/sh -c 'while tr\" 1 minute ago Up 11 minute evil_golick Note Container id is going to be different in your case Hint Instead of using full container-id when building commands, it is possible simply type first few characters of container-id, to make things nice and easy. Step 3 Let\u2019s use container-id to show the container standard output: docker logs <container-id> Thu Jan 26 00:23:45 UTC 2017 hello world Thu Jan 26 00:23:46 UTC 2017 hello world Thu Jan 26 00:23:47 UTC 2017 hello world ... As you can see, in the docker ps command output, the auto generated container name is evil_golick (your container can have a different name). Step 4 Now, instead of using docker contaier-id use container name to show the container standard output: docker logs <name> Thu Jan 26 00:23:51 UTC 2017 hello world Thu Jan 26 00:23:52 UTC 2017 hello world Thu Jan 26 00:23:53 UTC 2017 hello world ... Step 5 Finally, let\u2019s stop our container: docker stop <name> Step 6 Check, that there are no running containers: docker ps Summary docker logs is a very usefull command to troubleshoot containers, and going to be used very often both for Docker and Kubernertes troubleshooting.","title":"1.5 Run a container in a background"},{"location":"Lab_2_Docker_basics/#16-accessing-containers-from-the-internet","text":"Step 1 Let\u2019s run a simple web application. We will use the existing image training/webapp, which contains a Python Flask application: docker run -d -P training/webapp python app.py ... Status: Downloaded newer image for training/webapp:latest 6e88f42d3d853762edcbfe1fe73fdc5c48865275bc6df759b83b0939d5bd2456 In the command above we specified the main process (python app.py), the -d command line argument, which tells Docker to run the container in the background. The -P command line argument tells Docker to map any required network ports inside our container to our host. This allows us to access the web application in the container. Step 2 Use the docker ps command to list running containers: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6e88f42d3d85 training/webapp \"python app.py\" 3 minutes ago Up 3 minutes 0.0.0.0:32768->5000/tcp determined_torvalds The PORTS column contains the mapped ports. In our case, Docker has exposed port 5000 (the default Python Flask port) on port 32768 (can be different in your case). Step 3 The docker port command shows the exposed port. We will use the container name (determined_torvalds in the example above, it can be different in your case): docker port <name> 5000 0.0.0.0:32768 Step 4 Let\u2019s check that we can access the web application exposed port: curl http://localhost:<port>/ Result Hello world! Step 5 Let\u2019s stop our web application for now: docker stop <name> Step 6 We want to manually specify the local port to expose (-p argument). Let\u2019s use the standard HTTP port 80. We also want to specify the container name (--name argument): docker run -d -p 80:5000 --name webapp training/webapp python app.py Step 7 Let\u2019s check that the port 80 is exposed: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 249476631f7d training/webapp \"python app.py\" 1 minute ago Up 1 minute 0.0.0.0:80->5000/tcp webapp curl http://localhost/ Result `Hello world!`` Step 8 You can also observe Hello world! webapp from you laptop, for that you need to use you public VM IP that can be gather from VMs list: Your_VM_Public_IP Than paste VM Public IP address in you browser. Result Our web-app can be accessed from Internet!","title":"1.6 Accessing Containers from the Internet"},{"location":"Lab_2_Docker_basics/#17-restart-a-container","text":"Step 1 Let\u2019s stop the container with web application: docker stop webapp The main process inside of the container will receive SIGTERM, and after a grace period, SIGKILL. Step 2 You can start the container later using the docker start command: docker start webapp Step 3 Check that the web application works: curl http://localhost/ Hello world! Step 4 You also can restart the running container using the docker restart command. docker restart webapp Step 4 Run docker ps command and check STATUS field: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS 6e400179070f training/webapp \"python app.py\" 25 minutes ago Up 3 seconds","title":"1.7 Restart a container"},{"location":"Lab_2_Docker_basics/#18-ensuring-container-uptime","text":"Docker considers any containers to exit with a non-zero exit code to have crashed. By default a crashed container will remain stopped. Step 1 Start the container that outputs a message and then exits with code 1 to simulate a crash. docker run -d --name restart-default scrapbook/docker-restart-example docker ps -a | grep restart-default CONTAINER ID IMAGE CREATED STATUS NAMES c854289d2f39 scrapbook/docker-restart-example 5 seconds ago Exited 3 sec ago restart-default $ docker logs restart-default Sun Sep 17 20:34:55 UTC 2017 Booting up... Result Container crushed and exited. However, there are several ways to ensure that you container up and running even if it\u2019s restarts. Step 2 The option --restart=on-failure : allows you to say how many times Docker should try again: docker run -d --name restart-3 --restart=on-failure:3 scrapbook/docker-restart-example docker logs restart-3 Thu Apr 20 14:01:27 UTC 2017 Booting up... Thu Apr 20 14:01:28 UTC 2017 Booting up... Thu Apr 20 14:01:29 UTC 2017 Booting up... Thu Apr 20 14:01:31 UTC 2017 Booting up... Step 3 Finally, Docker can always restart a failed container. In this case, Docker will keep trying until the container is explicitly told to stop. docker run -d --name restart-always --restart=always scrapbook/docker-restart-example docker logs restart-always Step 4 After sometime stop running docker container, as it will be keep failing and starting again: docker stop restart-always","title":"1.8 Ensuring Container Uptime"},{"location":"Lab_2_Docker_basics/#19-inspect-a-container","text":"Step 1 You can use the docker inspect command to see the configuration and status information for the specified container: docker inspect webapp [ { \"Id\": \"249476631f7d...\", \"Created\": \"2016-08-02T23:42:56.932135327Z\", \"Path\": \"python\", \"Args\": [ \"app.py\" ], \"State\": { \"Status\": \"running\", \"Running\": true, \"Paused\": false, \"Restarting\": false, \"OOMKilled\": false, \"Dead\": false, \"Pid\": 16055, \"ExitCode\": 0, \"Error\": \"\", ... Step 2 You can specify a filter (-f command line argument) to show only specific elements. For example: docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' webapp 172.17.0.2 The command returns the IP address of the container.","title":"1.9 Inspect a container"},{"location":"Lab_2_Docker_basics/#110-interacting-with-containers","text":"In some cases using docker log is not enough to undertand issues and you want to login inside of running VM. Also sometimes you package you applicaiton and in order to run it you need to login inside of container and execute and leave it running in background. Below provded few ways to interacting with containers that can help to achive descrined use cases.","title":"1.10 Interacting with containers"},{"location":"Lab_2_Docker_basics/#1101-detach-from-interactive-container","text":"In Module, 1.4 Run an interactive container we run an Ubuntu container with -it flag and able directly login inside of the container to interact with it, however after we exited contianer using Ctrl-D or exit command container stopped. However you can exit from Interactive mode without stoping a container. Let's demonstrate how this works: Step 1 Start Ubunu container in interactive mode: docker run -it ubuntu /bin/bash Step 2 Run watch date command inside running container in order to exit date command every 2 seconds. root@1d688a9f4ed4:/# watch date Step 3 Detach from a container and leave it running using the CTRL-p CTRL-q key sequence. Step 4 Verify that Ubuntu container is still running: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS NAMES 1d688a9f4ed4 ubuntu \"/bin/bash\" 1 minutes ago Up 1 minutes admiring_lovelace Result Great you were able to detach from Docker container without stopping it, while it is executing a process in it. What about attaching back to container ? Important CTRL-p CTRL-q sequence key only works if docker contaienr started with -it command!","title":"1.10.1 Detach from Interactive container"},{"location":"Lab_2_Docker_basics/#1112-attach-to-a-container","text":"Now let's get back and attach to our running Ubuntu image. For that docker provides docker attach command. docker attach <container name> Every 2.0s: date Mon Sep 18 00:08:57 2017 Summary docker attach attaches your contairs terminal\u2019s standard input, output, and error (or any combination of the 3) to a running container. This allows you to view its ongoing output or to control it interactively, as though the commands were running directly in your terminal.","title":"1.11.2 Attach to a container"},{"location":"Lab_2_Docker_basics/#1113-execute-a-process-in-a-container","text":"Step 1 Let verify if webapp container is still running docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 249476631f7d training/webapp \"python app.py\" 1 minute ago Up 1 minute 0.0.0.0:80->5000/tcp webapp If not running start it with following command: $ docker run -d -p 80:5000 --name webapp training/webapp python app.py other wise skip to next step . Step 2 Use the docker exec command to execute a command in the running container. For example: docker exec webapp ps aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.2 0.0 52320 17384 ? Ss 00:11 0:00 python app.py root 26 0.0 0.0 15572 2104 ? Rs 00:12 0:00 ps aux The same command with the -it command line argument can be used to run an interactive session in the container: docker exec -it webapp bash root@249476631f7d:/opt/webapp# ps auxw ps auxw USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 1 0.0 0.0 52320 17384 ? Ss 00:11 0:00 python app.py root 32 0.0 0.0 18144 3064 ? Ss 00:14 0:00 bash root 47 0.0 0.0 15572 2076 ? R+ 00:16 0:00 ps auxw Step 2 Use the exit command or press Ctrl-D to exit the interactive bash session: root@249476631f7d:/opt/webapp# exit Summary docker exec is one of the most usefull docker commands used for troubleshooting containers.","title":"1.11.3 Execute a process in a container"},{"location":"Lab_2_Docker_basics/#112-copy-files-tofrom-container","text":"The docker cp command allows you to copy files from the container to the local machine or from the local file system to the container. This command works for a running or stopped container. Step 1 Let\u2019s copy the container\u2019s app.py file to the local machine: docker cp webapp:/opt/webapp/app.py . Step 2 Edit the local app.py file. For example, change the line return 'Hello '+provider+'!' to return 'Hello '+provider+'!!!'. Copy the modified file back and restart the container: docker cp app.py webapp:/opt/webapp/ docker restart webapp Step 3 Check that the modified web application works:: curl http://localhost/ Result `Hello world!!!``","title":"1.12 Copy files to/from container"},{"location":"Lab_2_Docker_basics/#112-remove-containers","text":"Now let's clean up the environment and at the same time learn how delete containers. Step 1 First list running containers: docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 81c4c66baaf9 training/webapp \"python app.py\" 1 minute ago Up 1 minute 0.0.0.0:80->5000/tcp webapp Step 2 Than try to delete running container using docker rm <container_id> docker rm $container_id Error response from daemon: You cannot remove a running container 81c4c66baaf9. Stop the container before attempting removal or force remove. Failure Docker containers needs to be first stopped or deleted using --force flag. docker rm $container_id -f Alternatively, you can run stop and rm in sequence: docker stop 81c4c66baaf9 docker rm 81c4c66baaf9 Summary We've learned a lot of docker commands which are very handy to know both when using Docker and Kubernetes. In the next Module we going to deep dive in to details of how networking and storage works in Docker.","title":"1.12 Remove containers"},{"location":"Lab_3_Advanced_Docker/","text":"Lab 3 Docker Networking, Persistence, Monitoring and Logging Objective: Networks Docker basics User-defined private Networks Persistence Data Volumes 1 Docker Networking \u00b6 1.1 Docker Networking Basics \u00b6 Step 1: The Docker Network Command The docker network command is the main command for configuring and managing container networks. Run the docker network command from the first terminal. docker network Usage: docker network COMMAND Manage networks Options: --help Print usage Commands: connect Connect a container to a network create Create a network disconnect Disconnect a container from a network inspect Display detailed information on one or more networks ls List networks prune Remove all unused networks rm Remove one or more networks Run 'docker network COMMAND --help' for more information on a command. The command output shows how to use the command as well as all of the docker network sub-commands. As you can see from the output, the docker network command allows you to create new networks, list existing networks, inspect networks, and remove networks. It also allows you to connect and disconnect containers from networks. Step 2 Run a docker network ls command to view existing container networks on the current Docker host. docker network ls NETWORK ID NAME DRIVER SCOPE 3430ad6f20bf bridge bridge local a7449465c379 host host local 06c349b9cc77 none null local The output above shows the container networks that are created as part of a standard installation of Docker. New networks that you create will also show up in the output of the docker network ls command. You can see that each network gets a unique ID and NAME . Each network is also associated with a single driver. Notice that the \"bridge\" network and the \"host\" network have the same name as their respective drivers. Step 3: The docker network inspect command is used to view network configuration details. These details include; name, ID, driver, IPAM driver, subnet info, connected containers, and more. Use docker network inspect <network> to view configuration details of the container networks on your Docker host. The command below shows the details of the network called bridge . docker network inspect bridge [ { \"Name\": \"bridge\", \"Id\": \"3430ad6f20bf1486df2e5f64ddc93cc4ff95d81f59b6baea8a510ad500df2e57\", \"Created\": \"2017-04-03T16:49:58.6536278Z\", \"Scope\": \"local\", \"Driver\": \"bridge\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": null, \"Config\": [ { \"Subnet\": \"172.17.0.0/16\", \"Gateway\": \"172.17.0.1\" } ] }, \"Internal\": false, \"Attachable\": false, \"Containers\": {}, \"Options\": { \"com.docker.network.bridge.default_bridge\": \"true\", \"com.docker.network.bridge.enable_icc\": \"true\", \"com.docker.network.bridge.enable_ip_masquerade\": \"true\", \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\", \"com.docker.network.bridge.name\": \"docker0\", \"com.docker.network.driver.mtu\": \"1500\" }, \"Labels\": {} } ] Note The syntax of the docker network inspect command is docker network inspect <network> , where <network> can be either network name or network ID. In the example above we are showing the configuration details for the network called \"bridge\". Do not confuse this with the \"bridge\" driver. Step 4 Now, list Docker supported network driver plugins. For that run docker info command, that shows a lot of interesting information about a Docker installation. Run the docker info command and locate the list of network plugins. docker info Containers: 0 Running: 0 Paused: 0 Stopped: 0 Images: 0 Server Version: 17.03.1-ee-3 Storage Driver: aufs <Snip> Plugins: Volume: local Network: bridge host macvlan null overlay Swarm: inactive Runtimes: runc <Snip> The output above shows the bridge , host , macvlan , null , and overlay drivers. Summary We've quickly reviewed available docker networking commands as well as found what drivers current docker setup supports. 1.2 Default bridge network \u00b6 Every clean installation of Docker comes with a pre-built network called Default bridge network . Let's explore in more details how it works. Step 1 Verify this with the docker network ls . docker network ls NETWORK ID NAME DRIVER SCOPE 3430ad6f20bf bridge bridge local a7449465c379 host host local 06c349b9cc77 none null local Result The output above shows that the bridge network is associated with the bridge driver. It's important to note that the network and the driver are connected, but they are not the same. In this example the network and the driver have the same name - but they are not the same thing! The output above also shows that the bridge network is scoped locally. This means that the network only exists on this Docker host. This is true of all networks using the bridge driver - the bridge driver provides single-host networking. All networks created with the bridge driver are based on a Linux bridge (a.k.a. a virtual switch). Step 5 Start webapp in Default bridge network docker run -d -p 80:5000 --name webapp training/webapp python app.py Step 6 Check that the webapp and db containers are running: Command: docker ps 1.3 User-defined Private Networks \u00b6 So far we\u2019ve learned how Docker networking works with Docker default bridge network . With the introduction of user-defined networking in Docker 1.9, it is now possible to create multiple Docker bridges to allow network segregation within the same host or multi-host networking to allow communicate Docker containers between hosts. The commands are available through the Docker Engine CLI are: docker network create docker network connect docker network ls docker network rm docker network disconnect docker network inspect Let's demonstrate how to create a custom bridge network. Step 1 By default, Docker runs containers in the bridge network. You may want to isolate one or more containers in a separate network. Let\u2019s create a new network: docker network create my-network \\ -d bridge \\ --subnet 172.19.0.0/16 The -d bridge command line argument specifies the bridge network driver and the --subnet command line argument specifies the network segment in CIDR format. If you do not specify a subnet when creating a network, then Docker assigns a subnet automatically, so it is a good idea to specify a subnet to avoid potential conflicts with the existing networks. Below are some other options that are available with the bridge Driver: com.docker.network.bridge.enable_ip_masquerade: This instructs the Docker host to hide or masquerade all containers in this network behind the Docker host's interfaces if the container attempts to route off the local host . com.docker.network.bridge.name: This is the name you wish to give to the bridge. com.docker.network.bridge.enable_icc: This turns on or off Inter-Container Connectivity (ICC) mode for the bridge. com.docker.network.bridge.host_binding_ipv4: This defines the host interface that should be used for port binding. com.docker.network.driver.mtu: This sets MTU for containers attached to this bridge. Step 2 To check that the new network is created, execute docker network ls: docker network ls NETWORK ID NAME DRIVER SCOPE d428e49e4869 bridge bridge local 0d1f78528cc5 host host local 56ef0481820d my-network bridge local 4a07cef84617 none null local Step 3 Let\u2019s inspect the new network: docker network inspect my-network [ { \"Name\": \"my-network\", \"Id\": \"56ef0481820d...\", \"Scope\": \"local\", \"Driver\": \"bridge\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": {}, \"Config\": [ { \"Subnet\": \"172.19.0.0/16\" } ] }, \"Internal\": false, \"Containers\": {}, \"Options\": {}, \"Labels\": {} } ] Step 4 As expected, there are no containers connected to the my-network. Let\u2019s recreate the db container in the my-network: docker rm -f db docker run -d --network=my-network --name db training/postgres Step 5 Inspect the my-network again: docker network inspect my-network Output: \"Containers\": { \"93af62cdab64...\": { \"Name\": \"db\", \"EndpointID\": \"b1e8e314cff0...\", \"MacAddress\": \"02:42:ac:12:00:02\", \"IPv4Address\": \"172.19.0.2/16\", \"IPv6Address\": \"\" } }, ... As you see, the db container is connected to the my-network and has 172.19.0.2 address. Step 6 Let\u2019s start an interactive session in the db container and ping the IP address of the webapp again: Note Quick reminder how to locate webapp ip: docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' webapp docker exec -it db bash Once inside of container run: root@c3afff20019a:/# ping -c 1 172.17.0.3 PING 172.17.0.3 (172.17.0.3) 56(84) bytes of data. --- 172.17.0.3 ping statistics --- 1 packets transmitted, 0 received, 100% packet loss, time 0ms As expected, the webapp container is no longer accessible from the db container, because they are connected to different networks. Summary Using Multi-host networking provides network isolation within a Docker host via network namepsaces. This is can be used if you want to deploy different applications on same host for isolation or resource duplicate prevention. Step 7 Let\u2019s connect the webapp container to the my-network: docker network connect my-network webapp Step 8 Check that the webapp container now is connected to the my-network: docker network inspect my-network Output: ... \"Containers\": { \"62ed4a627356...\": { \"Name\": \"webapp\", \"EndpointID\": \"ae95b0103bbc...\", \"MacAddress\": \"02:42:ac:12:00:03\", \"IPv4Address\": \"172.19.0.3/16\", \"IPv6Address\": \"\" }, \"93af62cdab64...\": { \"Name\": \"db\", \"EndpointID\": \"b1e8e314cff0...\", \"MacAddress\": \"02:42:ac:12:00:02\", \"IPv4Address\": \"172.19.0.2/16\", \"IPv6Address\": \"\" } }, ... The output shows that two containers are connected to the my-network and the webapp container has 172.19.0.3 address in that network. Step 9 Check that the webapp container is accessible from the db container using its new IP address: docker exec -it db bash root@c3afff20019a:/# ping -c 1 172.19.0.3 PING 172.19.0.3 (172.19.0.3) 56(84) bytes of data. 64 bytes from 172.19.0.3: icmp_seq=1 ttl=64 time=0.136 ms --- 172.19.0.3 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.136/0.136/0.136/0.000 ms Success As expected containers can communicate with each other. Step 10 You can now remove the existing container. You should stop the container before removing it. Alternatively you can use the -f command line argument: docker rm -f webapp docker rm -f db docker network rm my-network Hint Use below command to delete running containers in bulk : docker rm -f $(docker ps -q) Summary It is recommended to use user-defined bridge networks to control which containers can communicate with each other, and also to enable automatic DNS resolution of container names to IP addresses 1.4 Access containers from outside \u00b6 External Access to the Containers can be configured via publishing mechanism. Docker provides 2 options to publish ports: -P flag publishes all exposed ports -p flag allows you to specify specific ports and interfaces to use when mapping ports. The -p flag can take several different forms with the syntax looking like this: Specify the host port and container port: \u2013p <host port>:<container port> Specify the host interface, host port, and container port: \u2013p <host IP interface>:<host port>:<container port> Specify the host interface, have Docker choose a random host port, and specify the container port: \u2013p <host IP interface>::<container port> Specify only a container port and have Docker use a random host port: \u2013p <container port> Let's test exposing containers. For that let's start a new NGINX container and map port 8080 on the Docker host to port 80 inside of the container. This means that traffic that hits the Docker host on port 8080 will be passed on to port 80 inside the container. Note If you start a new container from the official NGINX image without specifying a command to run, the container will run a basic web server on port 80. Step 1 Start a new container based off the official NGINX image by running docker run --name web1 -d -p 8080:80 nginx . docker run --name web1 -d -p 8080:80 nginx Unable to find image 'nginx:latest' locally latest: Pulling from library/nginx 6d827a3ef358: Pull complete b556b18c7952: Pull complete 03558b976e24: Pull complete 9abee7e1ef9d: Pull complete Digest: sha256:52f84ace6ea43f2f58937e5f9fc562e99ad6876e82b99d171916c1ece587c188 Status: Downloaded newer image for nginx:latest 4e0da45b0f169f18b0e1ee9bf779500cb0f756402c0a0821d55565f162741b3e Step 2 Review the container status and port mappings by running docker ps . docker ps CONTAINER ID IMAGE COMMAND PORTS NAMES 4e0da45b0f16 nginx \"nginx -g 'daemon ...\" 443/tcp, 0.0.0.0:8080->80/tcp web1 Result The top line shows the new web1 container running NGINX. Take note of the command the container is running as well as the port mapping - 0.0.0.0:8080->80/tcp maps port 8080 on all host interfaces to port 80 inside the web1 container. This port mapping is what effectively makes the containers web service accessible from external sources (via the Docker hosts IP address on port 8080). Step 3 Test connectivity to the NGINX web server, by pasting <Public_IP:8080> of VM to the browser. Note In order to locate Public IP see the list of VMs. Alternatively from inside of VM run curl 127.0.0.1:8080 command. curl 127.0.0.1:8080 <!DOCTYPE html> <html> <Snip> <head> <title>Welcome to nginx!</title> <Snip> <p><em>Thank you for using nginx.</em></p> </body> </html> Success Both CLI and UI method works! If you try and curl the IP address on a different port number it will fail. Summary Docker provides easy way to expose containers outside of the Docker Node. This can ber used for connecting containers between each other: Between networks on the same host Between networks on different host Accessing containers from outside (e.g web site) However, port mapping is implemented via port address translation (PAT) unlike in Kubernetes which we learn soon, exposes applications via service IPs and communicates via POD IPs using (NAT) Step 4 Cleanup environment docker rm -f $(docker ps -q) 2 Persistant Volumes \u00b6 2.1 Storage driver \u00b6 We've discussed several Storage drivers (graphdrivers) during the class. Let's find out what graphdriver is running in our Lab environment. docker info | grep Storage WARNING: No swap limit support Storage Driver: aufs Result Our Classroom is running aufs storage driver. Not a suprise as we running our Lab on Ubuntu VM. Summary Systems runnng Ubuntu or Debian ,going to run aufs graphdriver by default and will most likely meet the majority of your needs. In future overlay2 may replace aufs stay tunned! 2.2 Persisting Data Using Volumes \u00b6 Docker Volumes are created and assigned when containers are started. Data Volumes allow you to map a host directory to a container for sharing data. This mapping is bi-directional. It allows data stored on the host to be accessed from within the container. It also means data saved by the process inside the container is persisted on the host. 2.2.1 Create and manage volumes \u00b6 Step 1 Create a volume: docker volume create --name my-vol Step 2 List volumes: docker volume ls Output: local my-vol Step 3 Inspect a volume: docker volume inspect my-vol [ { \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/var/lib/docker/volumes/my-vol/_data\", \"Name\": \"my-vol\", \"Options\": {}, \"Scope\": \"local\" } ] Step 3 Add some data to the Mountpoint of the volume: sudo touch /var/lib/docker/volumes/my-vol/_data/test_vol sudo ls /var/lib/docker/volumes/my-vol/_data/ Step 4 Create a container busybox alpine image and attach created my-vol volume in to it: docker run -it -v my-vol:/world busybox / # ls /world test_vol / # Result Volume is mounted and test_vol file is under /world folder as expected Step 5 Try to delete the volume: docker volume rm my-vol Error response from daemon: unable to remove volume: remove my-vol: volume is in use - [6ef3055b516b306847150af8fcea796c02cd90578967802ac29c39d3a2c90102] Failure Deleting container that is attached is not permited. However you can delete with -f option Step 5 Busybox container stopped, howerver it is not deleted. Let's locate stopped busybox container and delete it: docker ps -a | grep busybox docker rm $docker_id Step 6 You can now delete my-vol Note Volume is still avaiable if needed to be reattached any time docker volume ls docker volume rm my-vol docker volume ls Summary Volumes can be craeted and managed separately from containers. 2.2.2 Start a container with a volume \u00b6 If you start a container with a volume that does not yet exist, Docker creates the volume for you. Step 1 Add a data volume to a container: docker run -d -P --name webapp -v /webapp training/webapp python app.py Result Command started a new container and created a new volume inside the container at /webapp. Step 2 Locate the volume on the host using the docker inspect command: docker inspect webapp | grep -A9 Mounts ``` **Output:** ``` \"Mounts\": [ { \"Type\": \"volume\", \"Name\": \"39885c52758dcf7516513be2d44a17560e42b6da75aba30bc66d4af41df5384d\", \"Source\": \"/var/lib/docker/volumes/39885c52758dcf7516513be2d44a17560e42b6da75aba30bc66d4af41df5384d/_data\", \"Destination\": \"/webapp\", \"Driver\": \"local\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"\" Step 3 List container docker volume ls Output: DRIVER VOLUME NAME local 39885c52758dcf7516513be2d44a17560e42b6da75aba30bc66d4af41df5384d Step 5 Alternatively, you can specify a host directory you want to use as a data volume: mkdir db docker run -d --name db -v ~/db:/db training/postgres Step 2 Start an interactive session in the db container and create a new file in the /db directory: docker exec -it db bash Type inside docker containers console: root@9a7a4fbcc929:/# cd /db root@9a7a4fbcc929:/db# touch hello_from_db_container root@9a7a4fbcc929:/db# exit Step 4 Check that the local db directory contains the new file: ls db hello_from_db_container Step 5 Check that the data volume is persistent. Remove the db container: docker rm -f db Step 6 Create the db container again: docker run -d --name db -v ~/db:/db training/postgres Step 7 Check that its /db directory contains the hello_from_db_container file: docker exec -it db bash Run commands inside container: root@47a60c01590e:/# ls /db hello_from_db_container root@47a60c01590e:/# exit 2.2.3 Use a read-only volume \u00b6 Step 1 Mounting Volumes gives the container full read and write access to the directory. You can specify read-only permissions on the directory by adding the permissions :ro to the mount. If the container attempts to modify data within the directory it will error. docker run -d --name db1 -v ~/db:/db:ro training/postgres docker exec -it db1 bash cd db touch test Result touch: cannot touch 'test': Read-only file system $ exit Step 2 Clean up containers and volumes: docker rm -f $(docker ps -q) docker volume ls Output DRIVER VOLUME NAME local 39885c52758dcf7516513be2d44a17560e42b6da75aba30bc66d4af41df5384d docker volume rm 39885c52758dcf7516513be2d44a17560e42b6da75aba30bc66d4af41df5384d Summary We've learned how to manage volumes with containers Hint If you Docker host has several Storage plugins configured (e.g. ceph, gluster) you can specify via --opt type=btrfs, nfs or --driver=glusterfs during docker volume creation.","title":"Lab 3 Advanced Docker"},{"location":"Lab_3_Advanced_Docker/#1-docker-networking","text":"","title":"1 Docker Networking"},{"location":"Lab_3_Advanced_Docker/#11-docker-networking-basics","text":"Step 1: The Docker Network Command The docker network command is the main command for configuring and managing container networks. Run the docker network command from the first terminal. docker network Usage: docker network COMMAND Manage networks Options: --help Print usage Commands: connect Connect a container to a network create Create a network disconnect Disconnect a container from a network inspect Display detailed information on one or more networks ls List networks prune Remove all unused networks rm Remove one or more networks Run 'docker network COMMAND --help' for more information on a command. The command output shows how to use the command as well as all of the docker network sub-commands. As you can see from the output, the docker network command allows you to create new networks, list existing networks, inspect networks, and remove networks. It also allows you to connect and disconnect containers from networks. Step 2 Run a docker network ls command to view existing container networks on the current Docker host. docker network ls NETWORK ID NAME DRIVER SCOPE 3430ad6f20bf bridge bridge local a7449465c379 host host local 06c349b9cc77 none null local The output above shows the container networks that are created as part of a standard installation of Docker. New networks that you create will also show up in the output of the docker network ls command. You can see that each network gets a unique ID and NAME . Each network is also associated with a single driver. Notice that the \"bridge\" network and the \"host\" network have the same name as their respective drivers. Step 3: The docker network inspect command is used to view network configuration details. These details include; name, ID, driver, IPAM driver, subnet info, connected containers, and more. Use docker network inspect <network> to view configuration details of the container networks on your Docker host. The command below shows the details of the network called bridge . docker network inspect bridge [ { \"Name\": \"bridge\", \"Id\": \"3430ad6f20bf1486df2e5f64ddc93cc4ff95d81f59b6baea8a510ad500df2e57\", \"Created\": \"2017-04-03T16:49:58.6536278Z\", \"Scope\": \"local\", \"Driver\": \"bridge\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": null, \"Config\": [ { \"Subnet\": \"172.17.0.0/16\", \"Gateway\": \"172.17.0.1\" } ] }, \"Internal\": false, \"Attachable\": false, \"Containers\": {}, \"Options\": { \"com.docker.network.bridge.default_bridge\": \"true\", \"com.docker.network.bridge.enable_icc\": \"true\", \"com.docker.network.bridge.enable_ip_masquerade\": \"true\", \"com.docker.network.bridge.host_binding_ipv4\": \"0.0.0.0\", \"com.docker.network.bridge.name\": \"docker0\", \"com.docker.network.driver.mtu\": \"1500\" }, \"Labels\": {} } ] Note The syntax of the docker network inspect command is docker network inspect <network> , where <network> can be either network name or network ID. In the example above we are showing the configuration details for the network called \"bridge\". Do not confuse this with the \"bridge\" driver. Step 4 Now, list Docker supported network driver plugins. For that run docker info command, that shows a lot of interesting information about a Docker installation. Run the docker info command and locate the list of network plugins. docker info Containers: 0 Running: 0 Paused: 0 Stopped: 0 Images: 0 Server Version: 17.03.1-ee-3 Storage Driver: aufs <Snip> Plugins: Volume: local Network: bridge host macvlan null overlay Swarm: inactive Runtimes: runc <Snip> The output above shows the bridge , host , macvlan , null , and overlay drivers. Summary We've quickly reviewed available docker networking commands as well as found what drivers current docker setup supports.","title":"1.1 Docker Networking Basics"},{"location":"Lab_3_Advanced_Docker/#12-default-bridge-network","text":"Every clean installation of Docker comes with a pre-built network called Default bridge network . Let's explore in more details how it works. Step 1 Verify this with the docker network ls . docker network ls NETWORK ID NAME DRIVER SCOPE 3430ad6f20bf bridge bridge local a7449465c379 host host local 06c349b9cc77 none null local Result The output above shows that the bridge network is associated with the bridge driver. It's important to note that the network and the driver are connected, but they are not the same. In this example the network and the driver have the same name - but they are not the same thing! The output above also shows that the bridge network is scoped locally. This means that the network only exists on this Docker host. This is true of all networks using the bridge driver - the bridge driver provides single-host networking. All networks created with the bridge driver are based on a Linux bridge (a.k.a. a virtual switch). Step 5 Start webapp in Default bridge network docker run -d -p 80:5000 --name webapp training/webapp python app.py Step 6 Check that the webapp and db containers are running: Command: docker ps","title":"1.2 Default bridge network"},{"location":"Lab_3_Advanced_Docker/#13-user-defined-private-networks","text":"So far we\u2019ve learned how Docker networking works with Docker default bridge network . With the introduction of user-defined networking in Docker 1.9, it is now possible to create multiple Docker bridges to allow network segregation within the same host or multi-host networking to allow communicate Docker containers between hosts. The commands are available through the Docker Engine CLI are: docker network create docker network connect docker network ls docker network rm docker network disconnect docker network inspect Let's demonstrate how to create a custom bridge network. Step 1 By default, Docker runs containers in the bridge network. You may want to isolate one or more containers in a separate network. Let\u2019s create a new network: docker network create my-network \\ -d bridge \\ --subnet 172.19.0.0/16 The -d bridge command line argument specifies the bridge network driver and the --subnet command line argument specifies the network segment in CIDR format. If you do not specify a subnet when creating a network, then Docker assigns a subnet automatically, so it is a good idea to specify a subnet to avoid potential conflicts with the existing networks. Below are some other options that are available with the bridge Driver: com.docker.network.bridge.enable_ip_masquerade: This instructs the Docker host to hide or masquerade all containers in this network behind the Docker host's interfaces if the container attempts to route off the local host . com.docker.network.bridge.name: This is the name you wish to give to the bridge. com.docker.network.bridge.enable_icc: This turns on or off Inter-Container Connectivity (ICC) mode for the bridge. com.docker.network.bridge.host_binding_ipv4: This defines the host interface that should be used for port binding. com.docker.network.driver.mtu: This sets MTU for containers attached to this bridge. Step 2 To check that the new network is created, execute docker network ls: docker network ls NETWORK ID NAME DRIVER SCOPE d428e49e4869 bridge bridge local 0d1f78528cc5 host host local 56ef0481820d my-network bridge local 4a07cef84617 none null local Step 3 Let\u2019s inspect the new network: docker network inspect my-network [ { \"Name\": \"my-network\", \"Id\": \"56ef0481820d...\", \"Scope\": \"local\", \"Driver\": \"bridge\", \"EnableIPv6\": false, \"IPAM\": { \"Driver\": \"default\", \"Options\": {}, \"Config\": [ { \"Subnet\": \"172.19.0.0/16\" } ] }, \"Internal\": false, \"Containers\": {}, \"Options\": {}, \"Labels\": {} } ] Step 4 As expected, there are no containers connected to the my-network. Let\u2019s recreate the db container in the my-network: docker rm -f db docker run -d --network=my-network --name db training/postgres Step 5 Inspect the my-network again: docker network inspect my-network Output: \"Containers\": { \"93af62cdab64...\": { \"Name\": \"db\", \"EndpointID\": \"b1e8e314cff0...\", \"MacAddress\": \"02:42:ac:12:00:02\", \"IPv4Address\": \"172.19.0.2/16\", \"IPv6Address\": \"\" } }, ... As you see, the db container is connected to the my-network and has 172.19.0.2 address. Step 6 Let\u2019s start an interactive session in the db container and ping the IP address of the webapp again: Note Quick reminder how to locate webapp ip: docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' webapp docker exec -it db bash Once inside of container run: root@c3afff20019a:/# ping -c 1 172.17.0.3 PING 172.17.0.3 (172.17.0.3) 56(84) bytes of data. --- 172.17.0.3 ping statistics --- 1 packets transmitted, 0 received, 100% packet loss, time 0ms As expected, the webapp container is no longer accessible from the db container, because they are connected to different networks. Summary Using Multi-host networking provides network isolation within a Docker host via network namepsaces. This is can be used if you want to deploy different applications on same host for isolation or resource duplicate prevention. Step 7 Let\u2019s connect the webapp container to the my-network: docker network connect my-network webapp Step 8 Check that the webapp container now is connected to the my-network: docker network inspect my-network Output: ... \"Containers\": { \"62ed4a627356...\": { \"Name\": \"webapp\", \"EndpointID\": \"ae95b0103bbc...\", \"MacAddress\": \"02:42:ac:12:00:03\", \"IPv4Address\": \"172.19.0.3/16\", \"IPv6Address\": \"\" }, \"93af62cdab64...\": { \"Name\": \"db\", \"EndpointID\": \"b1e8e314cff0...\", \"MacAddress\": \"02:42:ac:12:00:02\", \"IPv4Address\": \"172.19.0.2/16\", \"IPv6Address\": \"\" } }, ... The output shows that two containers are connected to the my-network and the webapp container has 172.19.0.3 address in that network. Step 9 Check that the webapp container is accessible from the db container using its new IP address: docker exec -it db bash root@c3afff20019a:/# ping -c 1 172.19.0.3 PING 172.19.0.3 (172.19.0.3) 56(84) bytes of data. 64 bytes from 172.19.0.3: icmp_seq=1 ttl=64 time=0.136 ms --- 172.19.0.3 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.136/0.136/0.136/0.000 ms Success As expected containers can communicate with each other. Step 10 You can now remove the existing container. You should stop the container before removing it. Alternatively you can use the -f command line argument: docker rm -f webapp docker rm -f db docker network rm my-network Hint Use below command to delete running containers in bulk : docker rm -f $(docker ps -q) Summary It is recommended to use user-defined bridge networks to control which containers can communicate with each other, and also to enable automatic DNS resolution of container names to IP addresses","title":"1.3 User-defined Private Networks"},{"location":"Lab_3_Advanced_Docker/#14-access-containers-from-outside","text":"External Access to the Containers can be configured via publishing mechanism. Docker provides 2 options to publish ports: -P flag publishes all exposed ports -p flag allows you to specify specific ports and interfaces to use when mapping ports. The -p flag can take several different forms with the syntax looking like this: Specify the host port and container port: \u2013p <host port>:<container port> Specify the host interface, host port, and container port: \u2013p <host IP interface>:<host port>:<container port> Specify the host interface, have Docker choose a random host port, and specify the container port: \u2013p <host IP interface>::<container port> Specify only a container port and have Docker use a random host port: \u2013p <container port> Let's test exposing containers. For that let's start a new NGINX container and map port 8080 on the Docker host to port 80 inside of the container. This means that traffic that hits the Docker host on port 8080 will be passed on to port 80 inside the container. Note If you start a new container from the official NGINX image without specifying a command to run, the container will run a basic web server on port 80. Step 1 Start a new container based off the official NGINX image by running docker run --name web1 -d -p 8080:80 nginx . docker run --name web1 -d -p 8080:80 nginx Unable to find image 'nginx:latest' locally latest: Pulling from library/nginx 6d827a3ef358: Pull complete b556b18c7952: Pull complete 03558b976e24: Pull complete 9abee7e1ef9d: Pull complete Digest: sha256:52f84ace6ea43f2f58937e5f9fc562e99ad6876e82b99d171916c1ece587c188 Status: Downloaded newer image for nginx:latest 4e0da45b0f169f18b0e1ee9bf779500cb0f756402c0a0821d55565f162741b3e Step 2 Review the container status and port mappings by running docker ps . docker ps CONTAINER ID IMAGE COMMAND PORTS NAMES 4e0da45b0f16 nginx \"nginx -g 'daemon ...\" 443/tcp, 0.0.0.0:8080->80/tcp web1 Result The top line shows the new web1 container running NGINX. Take note of the command the container is running as well as the port mapping - 0.0.0.0:8080->80/tcp maps port 8080 on all host interfaces to port 80 inside the web1 container. This port mapping is what effectively makes the containers web service accessible from external sources (via the Docker hosts IP address on port 8080). Step 3 Test connectivity to the NGINX web server, by pasting <Public_IP:8080> of VM to the browser. Note In order to locate Public IP see the list of VMs. Alternatively from inside of VM run curl 127.0.0.1:8080 command. curl 127.0.0.1:8080 <!DOCTYPE html> <html> <Snip> <head> <title>Welcome to nginx!</title> <Snip> <p><em>Thank you for using nginx.</em></p> </body> </html> Success Both CLI and UI method works! If you try and curl the IP address on a different port number it will fail. Summary Docker provides easy way to expose containers outside of the Docker Node. This can ber used for connecting containers between each other: Between networks on the same host Between networks on different host Accessing containers from outside (e.g web site) However, port mapping is implemented via port address translation (PAT) unlike in Kubernetes which we learn soon, exposes applications via service IPs and communicates via POD IPs using (NAT) Step 4 Cleanup environment docker rm -f $(docker ps -q)","title":"1.4 Access containers from outside"},{"location":"Lab_3_Advanced_Docker/#2-persistant-volumes","text":"","title":"2 Persistant Volumes"},{"location":"Lab_3_Advanced_Docker/#21-storage-driver","text":"We've discussed several Storage drivers (graphdrivers) during the class. Let's find out what graphdriver is running in our Lab environment. docker info | grep Storage WARNING: No swap limit support Storage Driver: aufs Result Our Classroom is running aufs storage driver. Not a suprise as we running our Lab on Ubuntu VM. Summary Systems runnng Ubuntu or Debian ,going to run aufs graphdriver by default and will most likely meet the majority of your needs. In future overlay2 may replace aufs stay tunned!","title":"2.1 Storage driver"},{"location":"Lab_3_Advanced_Docker/#22-persisting-data-using-volumes","text":"Docker Volumes are created and assigned when containers are started. Data Volumes allow you to map a host directory to a container for sharing data. This mapping is bi-directional. It allows data stored on the host to be accessed from within the container. It also means data saved by the process inside the container is persisted on the host.","title":"2.2 Persisting Data Using Volumes"},{"location":"Lab_3_Advanced_Docker/#221-create-and-manage-volumes","text":"Step 1 Create a volume: docker volume create --name my-vol Step 2 List volumes: docker volume ls Output: local my-vol Step 3 Inspect a volume: docker volume inspect my-vol [ { \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/var/lib/docker/volumes/my-vol/_data\", \"Name\": \"my-vol\", \"Options\": {}, \"Scope\": \"local\" } ] Step 3 Add some data to the Mountpoint of the volume: sudo touch /var/lib/docker/volumes/my-vol/_data/test_vol sudo ls /var/lib/docker/volumes/my-vol/_data/ Step 4 Create a container busybox alpine image and attach created my-vol volume in to it: docker run -it -v my-vol:/world busybox / # ls /world test_vol / # Result Volume is mounted and test_vol file is under /world folder as expected Step 5 Try to delete the volume: docker volume rm my-vol Error response from daemon: unable to remove volume: remove my-vol: volume is in use - [6ef3055b516b306847150af8fcea796c02cd90578967802ac29c39d3a2c90102] Failure Deleting container that is attached is not permited. However you can delete with -f option Step 5 Busybox container stopped, howerver it is not deleted. Let's locate stopped busybox container and delete it: docker ps -a | grep busybox docker rm $docker_id Step 6 You can now delete my-vol Note Volume is still avaiable if needed to be reattached any time docker volume ls docker volume rm my-vol docker volume ls Summary Volumes can be craeted and managed separately from containers.","title":"2.2.1  Create and manage volumes"},{"location":"Lab_3_Advanced_Docker/#222-start-a-container-with-a-volume","text":"If you start a container with a volume that does not yet exist, Docker creates the volume for you. Step 1 Add a data volume to a container: docker run -d -P --name webapp -v /webapp training/webapp python app.py Result Command started a new container and created a new volume inside the container at /webapp. Step 2 Locate the volume on the host using the docker inspect command: docker inspect webapp | grep -A9 Mounts ``` **Output:** ``` \"Mounts\": [ { \"Type\": \"volume\", \"Name\": \"39885c52758dcf7516513be2d44a17560e42b6da75aba30bc66d4af41df5384d\", \"Source\": \"/var/lib/docker/volumes/39885c52758dcf7516513be2d44a17560e42b6da75aba30bc66d4af41df5384d/_data\", \"Destination\": \"/webapp\", \"Driver\": \"local\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"\" Step 3 List container docker volume ls Output: DRIVER VOLUME NAME local 39885c52758dcf7516513be2d44a17560e42b6da75aba30bc66d4af41df5384d Step 5 Alternatively, you can specify a host directory you want to use as a data volume: mkdir db docker run -d --name db -v ~/db:/db training/postgres Step 2 Start an interactive session in the db container and create a new file in the /db directory: docker exec -it db bash Type inside docker containers console: root@9a7a4fbcc929:/# cd /db root@9a7a4fbcc929:/db# touch hello_from_db_container root@9a7a4fbcc929:/db# exit Step 4 Check that the local db directory contains the new file: ls db hello_from_db_container Step 5 Check that the data volume is persistent. Remove the db container: docker rm -f db Step 6 Create the db container again: docker run -d --name db -v ~/db:/db training/postgres Step 7 Check that its /db directory contains the hello_from_db_container file: docker exec -it db bash Run commands inside container: root@47a60c01590e:/# ls /db hello_from_db_container root@47a60c01590e:/# exit","title":"2.2.2 Start a container with a volume"},{"location":"Lab_3_Advanced_Docker/#223-use-a-read-only-volume","text":"Step 1 Mounting Volumes gives the container full read and write access to the directory. You can specify read-only permissions on the directory by adding the permissions :ro to the mount. If the container attempts to modify data within the directory it will error. docker run -d --name db1 -v ~/db:/db:ro training/postgres docker exec -it db1 bash cd db touch test Result touch: cannot touch 'test': Read-only file system $ exit Step 2 Clean up containers and volumes: docker rm -f $(docker ps -q) docker volume ls Output DRIVER VOLUME NAME local 39885c52758dcf7516513be2d44a17560e42b6da75aba30bc66d4af41df5384d docker volume rm 39885c52758dcf7516513be2d44a17560e42b6da75aba30bc66d4af41df5384d Summary We've learned how to manage volumes with containers Hint If you Docker host has several Storage plugins configured (e.g. ceph, gluster) you can specify via --opt type=btrfs, nfs or --driver=glusterfs during docker volume creation.","title":"2.2.3 Use a read-only volume"},{"location":"Lab_4_Docker_Images/","text":"Lab 4 Managing Docker Images Objective: Learn to build docker images using Dockerfiles. Store images in Docker Hub Learn alternative registry solutions (GCR) Prepare Lab Environment \u00b6 This lab can be executed in you GCP Cloud Environment using Google Cloud Shell. Open the Google Cloud Shell by clicking on the icon on the top right of the screen: Once opened, you can use it to run the instructions for this lab. 1 Building Docker Images \u00b6 In the previous modules, we learned how to use Docker images to run Docker containers. Docker images that we used have been downloaded from the Docker Hub, a Docker image registry maintained by Docker Inc. In this section we will create a simple web application from scratch. We will use Flask ( http://flask.pocoo.org/ ), a microframework for Python. Our application for each request will display a random picture from the defined set. In the next session we will create all necessary files for our application, build docker image and then push to Docker Hub and Quay. The code for this application is also available in GitHub: https://github.com/Cloud-Architects-Program/ycit019/tree/main/Module4/flask-app 1.1 Create DOCKERFILE \u00b6 Step 1 Clone git repo on you laptop: git clone https://github.com/Cloud-Architects-Program/ycit019 cd ~/ycit019/Module4/flask-app/ Step 2 In this directory, we see following files: flask-app/ Dockerfile app.py requirements.txt templates/ index.html Step 3 Let\u2019s review file app.py with the following content: from flask import Flask , render_template import random app = Flask ( __name__ ) # list of cat images images = [ \"https://media.giphy.com/media/mlvseq9yvZhba/giphy.gif\" , \"https://media.giphy.com/media/13CoXDiaCcCoyk/giphy.gif\" , \"https://media.giphy.com/media/LtVXu5s7KwlK8/giphy.gif\" , \"https://media.giphy.com/media/PekRU0CYIpXS8/giphy.gif\" , \"https://media.giphy.com/media/11quO2C07Sh2oM/giphy.gif\" , \"https://media.giphy.com/media/12HZukMBlutpoQ/giphy.gif\" , \"https://media.giphy.com/media/1HKaikaFqDt7i/giphy.gif\" , \"https://media.giphy.com/media/v6aOjy0Qo1fIA/giphy.gif\" , \"https://media.giphy.com/media/12bjQ7uASAaCKk/giphy.gif\" , \"https://media.giphy.com/media/HFcl9uhuCqzGU/giphy.gif\" ] @app . route ( '/' ) def index (): url = random . choice ( images ) return render_template ( 'index.html' , url = url ) if __name__ == \"__main__\" : app . run ( host = \"0.0.0.0\" ) Step 4 Below is the content of requirements.txt file: Flask==2.0.0 Step 5 Under directory templates observe index.html with the following content: < html > < head > < style type = \"text/css\" > body { background : black ; color : white ; } div . container { max-width : 500 px ; margin : 100 px auto ; border : 20 px solid white ; padding : 10 px ; text-align : center ; } h4 { text-transform : uppercase ; } </ style > </ head > < body > < div class = \"container\" > < h4 > Cat Gif of the day </ h4 > < img src = \"{{url}}\" /> </ div > </ body > </ html > Step 6 Let\u2019s review content of the Dockerfile: # Official Python Alpine Base image using Simple Tags # Image contains Python 3 and pip pre-installed, so no need to install them FROM python:3.9.5-alpine3.12 # Specify Working directory WORKDIR /usr/src/app # COPY requirements.txt /usr/src/app/ COPY requirements.txt ./ # Install Python Flask used by the Python app RUN pip install --no-cache-dir -r requirements.txt # Copy files required for the app to run COPY app.py ./ COPY templates/index.html ./templates/ # Make a record that the port number the container should be expose is: EXPOSE 5000 # run the application CMD [ \"python\" , \"./app.py\" ] 1.2 Build a Docker image \u00b6 Step 1 Now let\u2019s build our Docker image. In the command below, replace with your user name. This user name should be the same as you created when you registered on Docker Hub. Because we will publish our build image in the next step to your own Docker Hub. docker build -t <Docker-hub-user-name>/myfirstapp . Result Image has been buit Step 2 Where is your built image? It\u2019s in your machine\u2019s local Docker image registry, you can check that your image exists with command below: docker images Step 3 Now run a container in a background and expose a standard HTTP port (80), which is redirected to the container\u2019s port 5000: docker run -dp 80:5000 --name myfirstapp <Docker-hub-user-name>/myfirstapp Step 4 Use your browser to open the address http:// and check that the application works. Step 5 Stop the container and remove it: docker rm -f myfirstapp 1.2.2 Publish Docker Image to Docker Hub \u00b6 One of the most popular way to share and work with you images is to push them to the Docker Hub. Docker Hub is a registry of Docker images. You can think of the registry as a directory of all available Docker images. Step 1 (Optional) If you don\u2019t have a Docker account, sign up for one here . Make a note of your username and password. Step 2 Log in to your local machine. docker login Step 3 Now, publish your image to docker Hub. docker push <Docker-hub-user-name>/myfirstapp Step 4 Login to https://hub.docker.com and verify simage and tags. Result Image been pushed and can be observed in Docker Hub, with the tag latest. Step 5 It is also possible to specify a custom tag for image prior to push it to the registry Note Image Tag of the created myfirstapp : docker images Modify $docker_image_tag with myfirstapp:v1 image tag value: docker tag $docker_image_tag <Docker-hub-user-name>/myfirstapp:v1 docker push <Docker-hub-user-name>/myfirstapp:v1 Result Image been pushed and can be observed in Docker Hub. You can now observe 2 docker image one with the tag latest and another with tag v1 Step 6 You can now pull or run specified Docker images from any other location where docker engine is installed with following commands: docker pull <Docker-hub-user-name>/myfirstapp:latest docker pull <Docker-hub-user-name>/myfirstapp:v1 Result Images stored locally docker images Output: myfirstapp v1 f50f9524513f 1 hour ago 22 MB myfirstapp latest f50f9524513f 1 hour ago 22 MB Finally run images with specific tag: docker run <Docker-hub-user-name>/myfirstapp:v1 1.2.3 Pushing images to gcr.io \u00b6 In a similar manner we need to tag the image to prepare it to be pushed to gcr.io. We just need to change the registry, which is for gcr.io formatted as gcr.io/PROJECT_ID. Step 1 Get the Project ID: PROJECT_ID=$(gcloud config get-value project) Step 2 Enable the required APIs: gcloud services enable containerregistry.googleapis.com Step 3 Tag the image: Modify $docker_image_tag with myfirstapp:v1 image tag value: docker tag $docker_image_tag gcr.io/${PROJECT_ID}/myfirstapp:v1 $docker_image_tag Push the image to gcr.io: docker push gcr.io/${PROJECT_ID}/myfirstapp:v1 Step 4 Login to GCP console -> Container Registry -> Images Result Docker images has been pushed to GCR registry 1.2.3 Pushing images to Local Repository \u00b6 First, we need to spin up a local docker registry. This could be a use case if you want to deploy basic registry On-Prem. This registry will luck security features such as Authentication, SSL, scanning. If you interested to use Enterprise ready solution On-Prem consider: Jfrog Artifactory, RedHa's Clair, Docker Enterprise or open source CNCF project Harbor. Step 1 Deploy local registry docker run -d -p 5000:5000 --name registry registry:2.7.1 Step 2 In order to upload an image to a registry, we need to tag it properly Modify $docker_image_tag with myfirstapp:v1 image tag value: docker tag $docker_image_tag localhost:5000/myfirstapp:v1 Step 3 Now that we have an image tagged correctly, we can push it to our local registry docker push localhost:5000/myfirstapp:v1 Step 4 Let\u2019s now delete the local image, and pull it again from the local registry To delete the image, we need to first remove the container that depends on that image. Run docker ps and get the Container_ID for the container that uses myfirstapp:v1 Kill and delete that container by running the following command, but make sure to replace CONTAINER_ID, with the actual ID. docker rm CONTAINER_ID Result: The command will print back the container ID, which is an indication it was successful. Step 5 Run docker images to validate docker images Step 6 Now we can delete the docker image docker rmi localhost:5000/myfirstapp:v1 Step 7 Although the image is deleted locally, it is still in the registry and we can pull it back, or use it to deploy containers. docker run -dp 8080:5000 --name myfirstapp localhost:5000/myfirstapp:v1 Run docker images again to check how the image is available locally again. docker images Step 8 Cleanup: docker rm -f myfirstapp 1.2.4 Automated Builds with Google Cloud Build \u00b6 Live Demo: GCR Image scanning Setting Up Docker Image Auto-Build with Google Cloud Build based on Push to Branch Auto Deployment of Image to Cloud Run","title":"Lab 4 Managing Docker Images"},{"location":"Lab_4_Docker_Images/#prepare-lab-environment","text":"This lab can be executed in you GCP Cloud Environment using Google Cloud Shell. Open the Google Cloud Shell by clicking on the icon on the top right of the screen: Once opened, you can use it to run the instructions for this lab.","title":"Prepare Lab Environment"},{"location":"Lab_4_Docker_Images/#1-building-docker-images","text":"In the previous modules, we learned how to use Docker images to run Docker containers. Docker images that we used have been downloaded from the Docker Hub, a Docker image registry maintained by Docker Inc. In this section we will create a simple web application from scratch. We will use Flask ( http://flask.pocoo.org/ ), a microframework for Python. Our application for each request will display a random picture from the defined set. In the next session we will create all necessary files for our application, build docker image and then push to Docker Hub and Quay. The code for this application is also available in GitHub: https://github.com/Cloud-Architects-Program/ycit019/tree/main/Module4/flask-app","title":"1 Building Docker Images"},{"location":"Lab_4_Docker_Images/#11-create-dockerfile","text":"Step 1 Clone git repo on you laptop: git clone https://github.com/Cloud-Architects-Program/ycit019 cd ~/ycit019/Module4/flask-app/ Step 2 In this directory, we see following files: flask-app/ Dockerfile app.py requirements.txt templates/ index.html Step 3 Let\u2019s review file app.py with the following content: from flask import Flask , render_template import random app = Flask ( __name__ ) # list of cat images images = [ \"https://media.giphy.com/media/mlvseq9yvZhba/giphy.gif\" , \"https://media.giphy.com/media/13CoXDiaCcCoyk/giphy.gif\" , \"https://media.giphy.com/media/LtVXu5s7KwlK8/giphy.gif\" , \"https://media.giphy.com/media/PekRU0CYIpXS8/giphy.gif\" , \"https://media.giphy.com/media/11quO2C07Sh2oM/giphy.gif\" , \"https://media.giphy.com/media/12HZukMBlutpoQ/giphy.gif\" , \"https://media.giphy.com/media/1HKaikaFqDt7i/giphy.gif\" , \"https://media.giphy.com/media/v6aOjy0Qo1fIA/giphy.gif\" , \"https://media.giphy.com/media/12bjQ7uASAaCKk/giphy.gif\" , \"https://media.giphy.com/media/HFcl9uhuCqzGU/giphy.gif\" ] @app . route ( '/' ) def index (): url = random . choice ( images ) return render_template ( 'index.html' , url = url ) if __name__ == \"__main__\" : app . run ( host = \"0.0.0.0\" ) Step 4 Below is the content of requirements.txt file: Flask==2.0.0 Step 5 Under directory templates observe index.html with the following content: < html > < head > < style type = \"text/css\" > body { background : black ; color : white ; } div . container { max-width : 500 px ; margin : 100 px auto ; border : 20 px solid white ; padding : 10 px ; text-align : center ; } h4 { text-transform : uppercase ; } </ style > </ head > < body > < div class = \"container\" > < h4 > Cat Gif of the day </ h4 > < img src = \"{{url}}\" /> </ div > </ body > </ html > Step 6 Let\u2019s review content of the Dockerfile: # Official Python Alpine Base image using Simple Tags # Image contains Python 3 and pip pre-installed, so no need to install them FROM python:3.9.5-alpine3.12 # Specify Working directory WORKDIR /usr/src/app # COPY requirements.txt /usr/src/app/ COPY requirements.txt ./ # Install Python Flask used by the Python app RUN pip install --no-cache-dir -r requirements.txt # Copy files required for the app to run COPY app.py ./ COPY templates/index.html ./templates/ # Make a record that the port number the container should be expose is: EXPOSE 5000 # run the application CMD [ \"python\" , \"./app.py\" ]","title":"1.1 Create DOCKERFILE"},{"location":"Lab_4_Docker_Images/#12-build-a-docker-image","text":"Step 1 Now let\u2019s build our Docker image. In the command below, replace with your user name. This user name should be the same as you created when you registered on Docker Hub. Because we will publish our build image in the next step to your own Docker Hub. docker build -t <Docker-hub-user-name>/myfirstapp . Result Image has been buit Step 2 Where is your built image? It\u2019s in your machine\u2019s local Docker image registry, you can check that your image exists with command below: docker images Step 3 Now run a container in a background and expose a standard HTTP port (80), which is redirected to the container\u2019s port 5000: docker run -dp 80:5000 --name myfirstapp <Docker-hub-user-name>/myfirstapp Step 4 Use your browser to open the address http:// and check that the application works. Step 5 Stop the container and remove it: docker rm -f myfirstapp","title":"1.2 Build a Docker image"},{"location":"Lab_4_Docker_Images/#122-publish-docker-image-to-docker-hub","text":"One of the most popular way to share and work with you images is to push them to the Docker Hub. Docker Hub is a registry of Docker images. You can think of the registry as a directory of all available Docker images. Step 1 (Optional) If you don\u2019t have a Docker account, sign up for one here . Make a note of your username and password. Step 2 Log in to your local machine. docker login Step 3 Now, publish your image to docker Hub. docker push <Docker-hub-user-name>/myfirstapp Step 4 Login to https://hub.docker.com and verify simage and tags. Result Image been pushed and can be observed in Docker Hub, with the tag latest. Step 5 It is also possible to specify a custom tag for image prior to push it to the registry Note Image Tag of the created myfirstapp : docker images Modify $docker_image_tag with myfirstapp:v1 image tag value: docker tag $docker_image_tag <Docker-hub-user-name>/myfirstapp:v1 docker push <Docker-hub-user-name>/myfirstapp:v1 Result Image been pushed and can be observed in Docker Hub. You can now observe 2 docker image one with the tag latest and another with tag v1 Step 6 You can now pull or run specified Docker images from any other location where docker engine is installed with following commands: docker pull <Docker-hub-user-name>/myfirstapp:latest docker pull <Docker-hub-user-name>/myfirstapp:v1 Result Images stored locally docker images Output: myfirstapp v1 f50f9524513f 1 hour ago 22 MB myfirstapp latest f50f9524513f 1 hour ago 22 MB Finally run images with specific tag: docker run <Docker-hub-user-name>/myfirstapp:v1","title":"1.2.2 Publish Docker Image to Docker Hub"},{"location":"Lab_4_Docker_Images/#123-pushing-images-to-gcrio","text":"In a similar manner we need to tag the image to prepare it to be pushed to gcr.io. We just need to change the registry, which is for gcr.io formatted as gcr.io/PROJECT_ID. Step 1 Get the Project ID: PROJECT_ID=$(gcloud config get-value project) Step 2 Enable the required APIs: gcloud services enable containerregistry.googleapis.com Step 3 Tag the image: Modify $docker_image_tag with myfirstapp:v1 image tag value: docker tag $docker_image_tag gcr.io/${PROJECT_ID}/myfirstapp:v1 $docker_image_tag Push the image to gcr.io: docker push gcr.io/${PROJECT_ID}/myfirstapp:v1 Step 4 Login to GCP console -> Container Registry -> Images Result Docker images has been pushed to GCR registry","title":"1.2.3 Pushing images to gcr.io"},{"location":"Lab_4_Docker_Images/#123-pushing-images-to-local-repository","text":"First, we need to spin up a local docker registry. This could be a use case if you want to deploy basic registry On-Prem. This registry will luck security features such as Authentication, SSL, scanning. If you interested to use Enterprise ready solution On-Prem consider: Jfrog Artifactory, RedHa's Clair, Docker Enterprise or open source CNCF project Harbor. Step 1 Deploy local registry docker run -d -p 5000:5000 --name registry registry:2.7.1 Step 2 In order to upload an image to a registry, we need to tag it properly Modify $docker_image_tag with myfirstapp:v1 image tag value: docker tag $docker_image_tag localhost:5000/myfirstapp:v1 Step 3 Now that we have an image tagged correctly, we can push it to our local registry docker push localhost:5000/myfirstapp:v1 Step 4 Let\u2019s now delete the local image, and pull it again from the local registry To delete the image, we need to first remove the container that depends on that image. Run docker ps and get the Container_ID for the container that uses myfirstapp:v1 Kill and delete that container by running the following command, but make sure to replace CONTAINER_ID, with the actual ID. docker rm CONTAINER_ID Result: The command will print back the container ID, which is an indication it was successful. Step 5 Run docker images to validate docker images Step 6 Now we can delete the docker image docker rmi localhost:5000/myfirstapp:v1 Step 7 Although the image is deleted locally, it is still in the registry and we can pull it back, or use it to deploy containers. docker run -dp 8080:5000 --name myfirstapp localhost:5000/myfirstapp:v1 Run docker images again to check how the image is available locally again. docker images Step 8 Cleanup: docker rm -f myfirstapp","title":"1.2.3 Pushing images to Local Repository"},{"location":"Lab_4_Docker_Images/#124-automated-builds-with-google-cloud-build","text":"Live Demo: GCR Image scanning Setting Up Docker Image Auto-Build with Google Cloud Build based on Push to Branch Auto Deployment of Image to Cloud Run","title":"1.2.4 Automated Builds with Google Cloud Build"},{"location":"Lab_5_Docker_Compose/","text":"Lab 5 Docker Compose and Docker ecosystem Objective: Practice to use Docker Compose, 1 Docker Compose \u00b6 1 Docker Compose \u00b6 In this module, will guide you through the process of building a multi-container application using docker compose. The application code is available at GitHub: https://github.com/Cloud-Architects-Program/ycit019 1.1 Deploy Guestbook app with Compose \u00b6 Let\u2019s build another application. This time we going to create famous Guestbook application. Guestbook consists of three services. A redis-master node, a set of redis-slave that can be scaled and find the redis-master via its DNS name. And a PHP frontend that exposes itself on port 80. The resulting application allows you to leave short messages which are stored in the redis cluster. Step 1 Change directory to the guestbook cd ~/ycit019/Module5/guestbook/ ls Step 2 Let\u2019s review the docker-guestbook.yml file version: \"2\" services: redis-master: image: gcr.io/google_containers/redis:e2e ports: - \"6379\" redis-slave: image: gcr.io/google_samples/gb-redisslave:v1 ports: - \"6379\" environment: - GET_HOSTS_FROM=dns frontend: image: gcr.io/google-samples/gb-frontend:v4 ports: - \"80:80\" environment: - GET_HOSTS_FROM=dns Step 3 Let\u2019s run docker-guestbook.yml with compose export LD_LIBRARY_PATH=/usr/local/lib docker-compose -f docker-guestbook.yml up -d Creating network \"examples_default\" with the default driver Creating examples_redis-slave_1 Creating examples_frontend_1 Creating examples_redis-master_1 Note -d - Detached mode: Run containers in the background, print new container names. -f - Specify an alternate compose file (default: docker-compose.yml) Step 4 Check that all containers are running: docker ps CONTAINER ID IMAGE COMMAND d1006d1beee5 gcr.io/google-samples/gb-frontend:v4 \"apache2-foreground\" fb3a15fde23f gcr.io/google_containers/redis:e2e \"redis-server /etc...\" 326b94d4cdd7 gcr.io/google_samples/gb-redisslave:v1 \"/entrypoint.sh /b...\" Step 5 Test the application locally Now that we've launched the application containers, let's try to test the web application locally. You should be able to access the application at Google Cloud Web Preview Console: Note Web Preview using port 8080 by default. If you application using other port, you can edit this as needed. Success Nice you now have compose stuck up and running! Step 6 Cleanup environment: docker-compose -f docker-guestbook.yml down Stopping guestbook_frontend_1 ... done Stopping guestbook_redis-master_1 ... done Stopping guestbook_redis-slave_1 ... done Removing guestbook_frontend_1 ... done Removing guestbook_redis-master_1 ... done Removing guestbook_redis-slave_1 ... done Removing network guestbook_default 1.2 Deploy Voting App using Compose \u00b6 Step 1 Switch to Module5/example-voting-app folder : cd ~/ycit019/Module5/example-voting-app/ Step 2 The existing file docker-compose.yml defines several images: A voting-app container based on a Python image A result-app container based on a Node.js image A Redis container based on a redis image, to temporarily store the data. A worker app based on a dotnet image A Postgres container based on a postgres image App Architecture: Note that three of the containers are built from Dockerfiles, while the other two are images on Docker Hub. Let's review them closely: Step 3 Review files that going to be deployed with tree command. Alternatively view the files in gitrepo page here sudo apt install tree tree Step 5 Let\u2019s change the default port to expose. Edit the docker-compose.yml file and find the following lines: ports: - \"5000:80\" Change 5000 to 80: ports: - \"80:80\" Step 4 Verify Docker Compose version: docker-compose version Step 5 Use the docker-compose tool to launch your application: docker-compose up -d Step 6 Check that all containers are running, volumes created. Check compose state and logs : #Docker state docker ps docker volumes #Docker compose state docker-compose ps docker-compose logs Step 7 Step 7 Use your browser to open the address http://<Public_IP> and check that the application works. Public_IP Step 8 Cleanup up. docker-compose down Stopping examplevotingapp_worker_1 ... done Stopping examplevotingapp_redis_1 ... done Stopping examplevotingapp_result_1 ... done Stopping examplevotingapp_db_1 ... done Stopping examplevotingapp_vote_1 ... done Removing examplevotingapp_worker_1 ... done Removing examplevotingapp_redis_1 ... done Removing examplevotingapp_result_1 ... done Removing examplevotingapp_db_1 ... done Removing examplevotingapp_vote_1 ... done Removing network examplevotingapp_default Step 9 You Boss told you that the application has a bug. Update the the app by editing the vote/app.py file and change the following lines near the top of the file: vim vote/app.py Press 'i' option_a = os.getenv('OPTION_A', \"Cats\") option_b = os.getenv('OPTION_B', \"Dogs\") Step 10 Replace \u201cCats\u201d and \u201cDogs\u201d with two options of your choice. For example: option_a = os.getenv('OPTION_A', \"Java\") option_b = os.getenv('OPTION_B', \"Python\") Press 'wq!' Step 11 Use docker-compose tool to launch your Update application: docker-compose up -d Check the UI Bingo Let's see who wins the battle of Orchestrations! Step 8 Cleanup up docker-compose down Congratulations You are now docker expert! We were able to start 2 microservices application with docker compose. First microservice had 3 services. Second microservice had 5 servics written in 3 different languages and able to talk to each other. Summary So far we've learned docker-compose v2. docker-compose v3 is out of scope for this Lab. However you got the idea! Read the Docker-Compose documentation on new syntax. Also example of v3 version of voting-app is here for you reference. 2 Docker Security \u00b6 2.1 Scan images with Trivy \u00b6 Trivy (tri pronounced like trigger, vy pronounced like envy) is a simple and comprehensive vulnerability scanner for containers and other artifacts. A software vulnerability is a glitch, flaw, or weakness present in the software or in an Operating System. Trivy detects vulnerabilities of OS packages (Alpine, RHEL, CentOS, etc.) and application dependencies (Bundler, Composer, npm, yarn, etc.). Trivy is easy to use. Just install the binary and you're ready to scan. All you need to do for scanning is to specify a target such as an image name of the container. Step 1 Install Trivy sudo apt-get install wget apt-transport-https gnupg lsb-release wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo apt-key add - echo deb https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main | sudo tee -a /etc/apt/sources.list.d/trivy.list sudo apt-get update sudo apt-get install trivy Step 2 Specify an image name (and a tag). $ trivy image [YOUR_IMAGE_NAME] For example: $ trivy image python:3.4-alpine 2019-05-16T01:20:43.180+0900 INFO Updating vulnerability database... 2019-05-16T01:20:53.029+0900 INFO Detecting Alpine vulnerabilities... python:3.4-alpine3.9 (alpine 3.9.2) =================================== Total: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0) +---------+------------------+----------+-------------------+---------------+--------------------------------+ | LIBRARY | VULNERABILITY ID | SEVERITY | INSTALLED VERSION | FIXED VERSION | TITLE | +---------+------------------+----------+-------------------+---------------+--------------------------------+ | openssl | CVE-2019-1543 | MEDIUM | 1.1.1a-r1 | 1.1.1b-r1 | openssl: ChaCha20-Poly1305 | | | | | | | with long nonces | +---------+------------------+----------+-------------------+---------------+--------------------------------+ Step 3 Explore local images in your environment. 2.1 Follow Docker Best Practices \u00b6 Dockle - Container Image Linter for Security, Helping build the Best-Practice Docker Image, Easy to start Dockle helps you: Build Best Practice Docker images Build secure Docker images Checkpoints includes CIS Benchmarks Step 1 Install Dockle $ VERSION=$( curl --silent \"https://api.github.com/repos/goodwithtech/dockle/releases/latest\" | \\ grep '\"tag_name\":' | \\ sed -E 's/.*\"v([^\"]+)\".*/\\1/' \\ ) && curl -L -o dockle.deb https://github.com/goodwithtech/dockle/releases/download/v${VERSION}/dockle_${VERSION}_Linux-64bit.deb $ sudo dpkg -i dockle.deb && rm dockle.deb Step 2 Experiment with existing applications we've created in the class: $ dockle image [YOUR_IMAGE_NAME] e.g. dockle archy/myfirstapp output: WARN - CIS-DI-0001: Create a user for the container * Last user should not be root WARN - DKL-DI-0006: Avoid latest tag * Avoid 'latest' tag INFO - CIS-DI-0005: Enable Content trust for Docker * export DOCKER_CONTENT_TRUST=1 before docker pull/build INFO - CIS-DI-0006: Add HEALTHCHECK instruction to the container image * not found HEALTHCHECK statement INFO - DKL-LI-0003: Only put necessary files * Suspicious directory : tmp","title":"Lab 5 Docker Compose"},{"location":"Lab_5_Docker_Compose/#1-docker-compose","text":"","title":"1 Docker Compose"},{"location":"Lab_5_Docker_Compose/#1-docker-compose_1","text":"In this module, will guide you through the process of building a multi-container application using docker compose. The application code is available at GitHub: https://github.com/Cloud-Architects-Program/ycit019","title":"1 Docker Compose"},{"location":"Lab_5_Docker_Compose/#11-deploy-guestbook-app-with-compose","text":"Let\u2019s build another application. This time we going to create famous Guestbook application. Guestbook consists of three services. A redis-master node, a set of redis-slave that can be scaled and find the redis-master via its DNS name. And a PHP frontend that exposes itself on port 80. The resulting application allows you to leave short messages which are stored in the redis cluster. Step 1 Change directory to the guestbook cd ~/ycit019/Module5/guestbook/ ls Step 2 Let\u2019s review the docker-guestbook.yml file version: \"2\" services: redis-master: image: gcr.io/google_containers/redis:e2e ports: - \"6379\" redis-slave: image: gcr.io/google_samples/gb-redisslave:v1 ports: - \"6379\" environment: - GET_HOSTS_FROM=dns frontend: image: gcr.io/google-samples/gb-frontend:v4 ports: - \"80:80\" environment: - GET_HOSTS_FROM=dns Step 3 Let\u2019s run docker-guestbook.yml with compose export LD_LIBRARY_PATH=/usr/local/lib docker-compose -f docker-guestbook.yml up -d Creating network \"examples_default\" with the default driver Creating examples_redis-slave_1 Creating examples_frontend_1 Creating examples_redis-master_1 Note -d - Detached mode: Run containers in the background, print new container names. -f - Specify an alternate compose file (default: docker-compose.yml) Step 4 Check that all containers are running: docker ps CONTAINER ID IMAGE COMMAND d1006d1beee5 gcr.io/google-samples/gb-frontend:v4 \"apache2-foreground\" fb3a15fde23f gcr.io/google_containers/redis:e2e \"redis-server /etc...\" 326b94d4cdd7 gcr.io/google_samples/gb-redisslave:v1 \"/entrypoint.sh /b...\" Step 5 Test the application locally Now that we've launched the application containers, let's try to test the web application locally. You should be able to access the application at Google Cloud Web Preview Console: Note Web Preview using port 8080 by default. If you application using other port, you can edit this as needed. Success Nice you now have compose stuck up and running! Step 6 Cleanup environment: docker-compose -f docker-guestbook.yml down Stopping guestbook_frontend_1 ... done Stopping guestbook_redis-master_1 ... done Stopping guestbook_redis-slave_1 ... done Removing guestbook_frontend_1 ... done Removing guestbook_redis-master_1 ... done Removing guestbook_redis-slave_1 ... done Removing network guestbook_default","title":"1.1 Deploy Guestbook app with Compose"},{"location":"Lab_5_Docker_Compose/#12-deploy-voting-app-using-compose","text":"Step 1 Switch to Module5/example-voting-app folder : cd ~/ycit019/Module5/example-voting-app/ Step 2 The existing file docker-compose.yml defines several images: A voting-app container based on a Python image A result-app container based on a Node.js image A Redis container based on a redis image, to temporarily store the data. A worker app based on a dotnet image A Postgres container based on a postgres image App Architecture: Note that three of the containers are built from Dockerfiles, while the other two are images on Docker Hub. Let's review them closely: Step 3 Review files that going to be deployed with tree command. Alternatively view the files in gitrepo page here sudo apt install tree tree Step 5 Let\u2019s change the default port to expose. Edit the docker-compose.yml file and find the following lines: ports: - \"5000:80\" Change 5000 to 80: ports: - \"80:80\" Step 4 Verify Docker Compose version: docker-compose version Step 5 Use the docker-compose tool to launch your application: docker-compose up -d Step 6 Check that all containers are running, volumes created. Check compose state and logs : #Docker state docker ps docker volumes #Docker compose state docker-compose ps docker-compose logs Step 7 Step 7 Use your browser to open the address http://<Public_IP> and check that the application works. Public_IP Step 8 Cleanup up. docker-compose down Stopping examplevotingapp_worker_1 ... done Stopping examplevotingapp_redis_1 ... done Stopping examplevotingapp_result_1 ... done Stopping examplevotingapp_db_1 ... done Stopping examplevotingapp_vote_1 ... done Removing examplevotingapp_worker_1 ... done Removing examplevotingapp_redis_1 ... done Removing examplevotingapp_result_1 ... done Removing examplevotingapp_db_1 ... done Removing examplevotingapp_vote_1 ... done Removing network examplevotingapp_default Step 9 You Boss told you that the application has a bug. Update the the app by editing the vote/app.py file and change the following lines near the top of the file: vim vote/app.py Press 'i' option_a = os.getenv('OPTION_A', \"Cats\") option_b = os.getenv('OPTION_B', \"Dogs\") Step 10 Replace \u201cCats\u201d and \u201cDogs\u201d with two options of your choice. For example: option_a = os.getenv('OPTION_A', \"Java\") option_b = os.getenv('OPTION_B', \"Python\") Press 'wq!' Step 11 Use docker-compose tool to launch your Update application: docker-compose up -d Check the UI Bingo Let's see who wins the battle of Orchestrations! Step 8 Cleanup up docker-compose down Congratulations You are now docker expert! We were able to start 2 microservices application with docker compose. First microservice had 3 services. Second microservice had 5 servics written in 3 different languages and able to talk to each other. Summary So far we've learned docker-compose v2. docker-compose v3 is out of scope for this Lab. However you got the idea! Read the Docker-Compose documentation on new syntax. Also example of v3 version of voting-app is here for you reference.","title":"1.2 Deploy Voting App using Compose"},{"location":"Lab_5_Docker_Compose/#2-docker-security","text":"","title":"2 Docker Security"},{"location":"Lab_5_Docker_Compose/#21-scan-images-with-trivy","text":"Trivy (tri pronounced like trigger, vy pronounced like envy) is a simple and comprehensive vulnerability scanner for containers and other artifacts. A software vulnerability is a glitch, flaw, or weakness present in the software or in an Operating System. Trivy detects vulnerabilities of OS packages (Alpine, RHEL, CentOS, etc.) and application dependencies (Bundler, Composer, npm, yarn, etc.). Trivy is easy to use. Just install the binary and you're ready to scan. All you need to do for scanning is to specify a target such as an image name of the container. Step 1 Install Trivy sudo apt-get install wget apt-transport-https gnupg lsb-release wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo apt-key add - echo deb https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main | sudo tee -a /etc/apt/sources.list.d/trivy.list sudo apt-get update sudo apt-get install trivy Step 2 Specify an image name (and a tag). $ trivy image [YOUR_IMAGE_NAME] For example: $ trivy image python:3.4-alpine 2019-05-16T01:20:43.180+0900 INFO Updating vulnerability database... 2019-05-16T01:20:53.029+0900 INFO Detecting Alpine vulnerabilities... python:3.4-alpine3.9 (alpine 3.9.2) =================================== Total: 1 (UNKNOWN: 0, LOW: 0, MEDIUM: 1, HIGH: 0, CRITICAL: 0) +---------+------------------+----------+-------------------+---------------+--------------------------------+ | LIBRARY | VULNERABILITY ID | SEVERITY | INSTALLED VERSION | FIXED VERSION | TITLE | +---------+------------------+----------+-------------------+---------------+--------------------------------+ | openssl | CVE-2019-1543 | MEDIUM | 1.1.1a-r1 | 1.1.1b-r1 | openssl: ChaCha20-Poly1305 | | | | | | | with long nonces | +---------+------------------+----------+-------------------+---------------+--------------------------------+ Step 3 Explore local images in your environment.","title":"2.1 Scan images with Trivy"},{"location":"Lab_5_Docker_Compose/#21-follow-docker-best-practices","text":"Dockle - Container Image Linter for Security, Helping build the Best-Practice Docker Image, Easy to start Dockle helps you: Build Best Practice Docker images Build secure Docker images Checkpoints includes CIS Benchmarks Step 1 Install Dockle $ VERSION=$( curl --silent \"https://api.github.com/repos/goodwithtech/dockle/releases/latest\" | \\ grep '\"tag_name\":' | \\ sed -E 's/.*\"v([^\"]+)\".*/\\1/' \\ ) && curl -L -o dockle.deb https://github.com/goodwithtech/dockle/releases/download/v${VERSION}/dockle_${VERSION}_Linux-64bit.deb $ sudo dpkg -i dockle.deb && rm dockle.deb Step 2 Experiment with existing applications we've created in the class: $ dockle image [YOUR_IMAGE_NAME] e.g. dockle archy/myfirstapp output: WARN - CIS-DI-0001: Create a user for the container * Last user should not be root WARN - DKL-DI-0006: Avoid latest tag * Avoid 'latest' tag INFO - CIS-DI-0005: Enable Content trust for Docker * export DOCKER_CONTENT_TRUST=1 before docker pull/build INFO - CIS-DI-0006: Add HEALTHCHECK instruction to the container image * not found HEALTHCHECK statement INFO - DKL-LI-0003: Only put necessary files * Suspicious directory : tmp","title":"2.1 Follow Docker Best Practices"},{"location":"assignment1/","text":"1 Containerize Applications \u00b6 Objective: Review process of containerizing of applications Review creation of Docker Images Review build image process Prepare Lab Environment \u00b6 This lab can be executed in you GCP Cloud Environment using Google Cloud Shell. Open the Google Cloud Shell by clicking on the icon on the top right of the screen: Once opened, you can use it to run the instructions for this lab. 1.1 Overview of the Sample Application \u00b6 This package contains two application components which will be used throughout the course to demonstrate features of Kubernetes: gowebapp This directory contains a simple Go-based note-taking web application. It includes a home page, registration page, login page, about page, and note management page. Configuration for this application is stored in code/config/config.json. This file is used to configure the backing data store for the application, which in this course is MySQL. Later in the course, we will externalize this configuration in order to take advantage of Kubernetes Secrets and ConfigMaps. This will include some minor modifications to the Go source code. Go programming experience is not required to complete the exercises. For more details about the internal design and implementation of the Go web application, see code/README.md. gowebapp-mysql This directory contains the schema file used to setup the backing MySQL database for the Go web application. 1.1 Build Dockers image for frontend application \u00b6 Step 1 Locate and review the go source code: cd ~ git clone https://github.com/Cloud-Architects-Program/ycit019 cd ~/ycit019/Assignment1/ Result Two folders with go app and mysql config has been reviewed. Step 2 Setup vim editor with appropriate color schema Note Skip this step if you use another editor. echo \"colo elflord\" > ~/.vimrc Step 3 Write Dockerfile for your frontend application cd ~/ycit019/Assignment1/gowebapp Create a file named Dockerfile in this directory for the frontend Go app. Use vi or any preferred text editor. vim Dockerfile The template below provides a starting point for defining the contents of this file. Replace TODO comments with the appropriate commands: #TODO --- Define this image to inherit from the \"golang\" base image. Use version `1.15.11` or lower for `golang` #https://hub.docker.com/_/golang/ #https://docs.docker.com/engine/reference/builder/#from #TODO Set a label corresponding to the MAINTAINER field you could use, so that it wil be visible from docker inspect with the other labels. #MAINTAINER should be you student e-mail. #TODO --- Define a version label for this image #https://docs.docker.com/engine/reference/builder/#label EXPOSE 80 ENV GOPATH=/go #TODO --- Copy source code in the local /code directory into $GOPATH/src/gowebapp #https://docs.docker.com/engine/reference/builder/#copy WORKDIR $GOPATH/src/gowebapp/ RUN go get && go install #TODO --- Define an entrypoint for this image which executes the compiled application in $GOPATH/bin/gowebapp when the container starts #https://docs.docker.com/engine/reference/builder/#entrypoint Step 4 Build gowebapp Docker image locally Build the image locally. Make sure to include \".\" at the end. Make sure the build runs to completion without errors. You should get a success message. #TODO Build image `<your-github-user>/gowebapp:v1 1.2 Build Docker image for backend application \u00b6 Step 1 Locate folder with mysql config cd ~/ycit019/Assignment1/gowebapp-mysql Step 2 Write Dockerfile for your backend application Create a file named Dockerfile in this directory for the backend MySQL database application. Use vi or any preferred text editor. vim Dockerfile The template below provides a starting point for defining the contents of this file. Replace TODO comments with the appropriate commands: #TODO --- Define this image to inherit from the \"mysql\" version 8.0 base image #https://hub.docker.com/_/mysql/ #https://docs.docker.com/engine/reference/builder/#from #TODO Set a label corresponding to the MAINTAINER field you could use, so that it wil be visible from docker inspect with the other labels. #MAINTAINER should be you student e-mail. LABEL gowebapp-mysql \"v1\" #TODO --- Investigate the \"Initializing a Fresh Instance\" instructions for the mysql parent image, and copy the local gowebapp.sql file to the proper container directory to be automatically executed when the container starts up #https://hub.docker.com/_/mysql/ #https://docs.docker.com/engine/reference/builder/#copy Step 2 Build gowebapp-mysql Docker image locally #TODO Build image <your-github-user>/gowebapp-mysql:v1 Build the image locally. Make sure to include \".\" at the end. Make sure the build runs to completion without errors. You should get a success message. Run and test Docker images locally 1.3 Test application by running with Docker Engine. \u00b6 Before putting our app in production let's run the Docker images locally, to ensure that the frontend and backend containers run and integrate properly. Step 1 Create Docker user-defined network To facilitate cross-container communication, let's first define a user-defined network named gowebapp with subnet range 172.19.0.0/16 in which to run the frontend and backend containers: #TODO docker xxx Step 2 Launch backend container Next, let's launch a frontend and backend container using the Docker CLI. First, we launch the database container, as it will take a bit longer to startup, and the frontend container depends on it. Notice how we are injecting the database password into the MySQL configuration as an environment variable: #TODO Launch `backend` container in background #TODO Use this settings: `--name gowebapp-mysql` `--hostname gowebapp-mysql` #TODO Container needs to run on network: `gowebapp` #TODO Include following Env Variable in the command: `MYSQL_ROOT_PASSWORD=rootpasswd` Step 3 Launch frontend container Now launch a frontend container, mapping the container port 80 - where the web application is exposed - to port 8080 on the host machine: #TODO Launch `frontend` container in background #TODO Use this settings: `--name gowebapp` `--hostname gowebapp` #TODO Map the container port 80 - to port 8080 on the host machine #TODO Container needs to run on network: `gowebapp` Step 4 Test the application locally Now that we've launched the application containers, let's try to test the web application locally. You should be able to access the application at Google Cloud Web Preview Console: Note Web Preview using port 8080 by default. If you application using other port, you can edit this as needed. Once you can see the application loaded. Create an account and login. Write something on your Notepad and save it. This will verify that the application is working and properly integrates with the backend database container. Task Take a screenshot of running application. Step 5 Inspect the MySQL database Let's connect to the backend MySQL database container and run some queries to ensure that application persistence is working properly: #TODO docker xxx Step 6 Once inside the container, connect to MySQL database: mysql -u root -p password: Note Use password that has beed used in MYSQL_ROOT_PASSWORD env variable. Step 7 Once connected, run some simple SQL commands to inspect the database tables and persistence: #Simple SQL to navigate SHOW DATABASES; USE gowebapp; SHOW TABLES; SELECT * FROM <table_name>; exit; 1.5 Cleanup running applications and unused networks \u00b6 ### TODO docker xxx","title":"Assignment1"},{"location":"assignment1/#1-containerize-applications","text":"Objective: Review process of containerizing of applications Review creation of Docker Images Review build image process","title":"1 Containerize Applications"},{"location":"assignment1/#prepare-lab-environment","text":"This lab can be executed in you GCP Cloud Environment using Google Cloud Shell. Open the Google Cloud Shell by clicking on the icon on the top right of the screen: Once opened, you can use it to run the instructions for this lab.","title":"Prepare Lab Environment"},{"location":"assignment1/#11-overview-of-the-sample-application","text":"This package contains two application components which will be used throughout the course to demonstrate features of Kubernetes: gowebapp This directory contains a simple Go-based note-taking web application. It includes a home page, registration page, login page, about page, and note management page. Configuration for this application is stored in code/config/config.json. This file is used to configure the backing data store for the application, which in this course is MySQL. Later in the course, we will externalize this configuration in order to take advantage of Kubernetes Secrets and ConfigMaps. This will include some minor modifications to the Go source code. Go programming experience is not required to complete the exercises. For more details about the internal design and implementation of the Go web application, see code/README.md. gowebapp-mysql This directory contains the schema file used to setup the backing MySQL database for the Go web application.","title":"1.1 Overview of the Sample Application"},{"location":"assignment1/#11-build-dockers-image-for-frontend-application","text":"Step 1 Locate and review the go source code: cd ~ git clone https://github.com/Cloud-Architects-Program/ycit019 cd ~/ycit019/Assignment1/ Result Two folders with go app and mysql config has been reviewed. Step 2 Setup vim editor with appropriate color schema Note Skip this step if you use another editor. echo \"colo elflord\" > ~/.vimrc Step 3 Write Dockerfile for your frontend application cd ~/ycit019/Assignment1/gowebapp Create a file named Dockerfile in this directory for the frontend Go app. Use vi or any preferred text editor. vim Dockerfile The template below provides a starting point for defining the contents of this file. Replace TODO comments with the appropriate commands: #TODO --- Define this image to inherit from the \"golang\" base image. Use version `1.15.11` or lower for `golang` #https://hub.docker.com/_/golang/ #https://docs.docker.com/engine/reference/builder/#from #TODO Set a label corresponding to the MAINTAINER field you could use, so that it wil be visible from docker inspect with the other labels. #MAINTAINER should be you student e-mail. #TODO --- Define a version label for this image #https://docs.docker.com/engine/reference/builder/#label EXPOSE 80 ENV GOPATH=/go #TODO --- Copy source code in the local /code directory into $GOPATH/src/gowebapp #https://docs.docker.com/engine/reference/builder/#copy WORKDIR $GOPATH/src/gowebapp/ RUN go get && go install #TODO --- Define an entrypoint for this image which executes the compiled application in $GOPATH/bin/gowebapp when the container starts #https://docs.docker.com/engine/reference/builder/#entrypoint Step 4 Build gowebapp Docker image locally Build the image locally. Make sure to include \".\" at the end. Make sure the build runs to completion without errors. You should get a success message. #TODO Build image `<your-github-user>/gowebapp:v1","title":"1.1 Build Dockers image for frontend application"},{"location":"assignment1/#12-build-docker-image-for-backend-application","text":"Step 1 Locate folder with mysql config cd ~/ycit019/Assignment1/gowebapp-mysql Step 2 Write Dockerfile for your backend application Create a file named Dockerfile in this directory for the backend MySQL database application. Use vi or any preferred text editor. vim Dockerfile The template below provides a starting point for defining the contents of this file. Replace TODO comments with the appropriate commands: #TODO --- Define this image to inherit from the \"mysql\" version 8.0 base image #https://hub.docker.com/_/mysql/ #https://docs.docker.com/engine/reference/builder/#from #TODO Set a label corresponding to the MAINTAINER field you could use, so that it wil be visible from docker inspect with the other labels. #MAINTAINER should be you student e-mail. LABEL gowebapp-mysql \"v1\" #TODO --- Investigate the \"Initializing a Fresh Instance\" instructions for the mysql parent image, and copy the local gowebapp.sql file to the proper container directory to be automatically executed when the container starts up #https://hub.docker.com/_/mysql/ #https://docs.docker.com/engine/reference/builder/#copy Step 2 Build gowebapp-mysql Docker image locally #TODO Build image <your-github-user>/gowebapp-mysql:v1 Build the image locally. Make sure to include \".\" at the end. Make sure the build runs to completion without errors. You should get a success message. Run and test Docker images locally","title":"1.2 Build Docker image for backend application"},{"location":"assignment1/#13-test-application-by-running-with-docker-engine","text":"Before putting our app in production let's run the Docker images locally, to ensure that the frontend and backend containers run and integrate properly. Step 1 Create Docker user-defined network To facilitate cross-container communication, let's first define a user-defined network named gowebapp with subnet range 172.19.0.0/16 in which to run the frontend and backend containers: #TODO docker xxx Step 2 Launch backend container Next, let's launch a frontend and backend container using the Docker CLI. First, we launch the database container, as it will take a bit longer to startup, and the frontend container depends on it. Notice how we are injecting the database password into the MySQL configuration as an environment variable: #TODO Launch `backend` container in background #TODO Use this settings: `--name gowebapp-mysql` `--hostname gowebapp-mysql` #TODO Container needs to run on network: `gowebapp` #TODO Include following Env Variable in the command: `MYSQL_ROOT_PASSWORD=rootpasswd` Step 3 Launch frontend container Now launch a frontend container, mapping the container port 80 - where the web application is exposed - to port 8080 on the host machine: #TODO Launch `frontend` container in background #TODO Use this settings: `--name gowebapp` `--hostname gowebapp` #TODO Map the container port 80 - to port 8080 on the host machine #TODO Container needs to run on network: `gowebapp` Step 4 Test the application locally Now that we've launched the application containers, let's try to test the web application locally. You should be able to access the application at Google Cloud Web Preview Console: Note Web Preview using port 8080 by default. If you application using other port, you can edit this as needed. Once you can see the application loaded. Create an account and login. Write something on your Notepad and save it. This will verify that the application is working and properly integrates with the backend database container. Task Take a screenshot of running application. Step 5 Inspect the MySQL database Let's connect to the backend MySQL database container and run some queries to ensure that application persistence is working properly: #TODO docker xxx Step 6 Once inside the container, connect to MySQL database: mysql -u root -p password: Note Use password that has beed used in MYSQL_ROOT_PASSWORD env variable. Step 7 Once connected, run some simple SQL commands to inspect the database tables and persistence: #Simple SQL to navigate SHOW DATABASES; USE gowebapp; SHOW TABLES; SELECT * FROM <table_name>; exit;","title":"1.3 Test application by running with Docker Engine."},{"location":"assignment1/#15-cleanup-running-applications-and-unused-networks","text":"### TODO docker xxx","title":"1.5 Cleanup running applications and unused networks"}]}